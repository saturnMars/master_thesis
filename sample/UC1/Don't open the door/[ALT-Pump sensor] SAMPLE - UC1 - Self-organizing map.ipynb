{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "if '..' not in path:\n",
    "    path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import _library.som_utils as utils\n",
    "import _library.som_pre_utils as pre_utils\n",
    "import _library.fault_utils as fault_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv \n",
    "from _library.utils import SYSTEM_NAMES, SUBFOLDERS, load_datasets\n",
    "from os import path, makedirs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import Javascript\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd /mnt/data/vieri/projects/SAMPLE/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the pump dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "system_name = \"Pump sensor\"\n",
    "system_path = path.join(\"data\", system_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_path = path.join(system_path, \"sensor.csv\")\n",
    "\n",
    "# Read the csv file\n",
    "pump_sensor_df = pd.read_csv(file_path, index_col = 0)\n",
    "\n",
    "# Set the index as a fake 1-hour sampled timeseries (original: 1-minute sampled)\n",
    "pump_sensor_df.index = pd.date_range(start = '2022-01-01', periods = len(pump_sensor_df), freq = \"1H\")\n",
    "pump_sensor_df.drop(columns = ['timestamp'], inplace = True)\n",
    "\n",
    "# Drop artefacts\n",
    "pump_sensor_df.drop(['sensor_15','sensor_50'], axis=1, inplace=True)\n",
    "\n",
    "# Visualize the number of classes\n",
    "grouped_classes = pump_sensor_df.groupby('machine_status').count()['sensor_00'].to_frame()\\\n",
    "                                              .rename(columns = {'sensor_00': 'Observations'})\\\n",
    "                                              .sort_values(by ='Observations', ascending=False)\n",
    "display(grouped_classes)\n",
    "pump_sensor_df.info()\n",
    "display(pump_sensor_df[pump_sensor_df['machine_status'] == 'BROKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pump_sensor_df\n",
    "nominal_behaviour = df[df['machine_status'] == 'NORMAL']\n",
    "failure_events = df[df['machine_status'] == 'BROKEN']\n",
    "recovering_status = df[df['machine_status'] == 'RECOVERING']\n",
    "\n",
    "# Balance the classes\n",
    "temporal_tolerance = pd.Timedelta(10, unit=\"days\")\n",
    "failure_idk_obs = []\n",
    "for timestamp in failure_events.index:\n",
    "    df_period = df.loc[timestamp - temporal_tolerance:timestamp + temporal_tolerance, :]\n",
    "    failure_idk_obs.extend(df_period.index.tolist())\n",
    "#print(failure_obs[0])\n",
    "\n",
    "#recovering_obs = recovering_status.sample(frac = 0.4, random_state = 99)\n",
    "#nominal_obs = nominal_behaviour.sample(frac = 0.02, random_state = 99)\n",
    "\n",
    "# Compute the indexes\n",
    "idk_test = sorted(failure_idk_obs)  #+ random_recovering_obs.index.tolist() + random_nominal_obs.index.tolist()\n",
    "idk_train = list(sorted(set(df.index.tolist()) - set(idk_test)))\n",
    "\n",
    "# Create the two subsets\n",
    "train_data = df.loc[idk_train,:].iloc[:50000]\n",
    "test_data =  df.loc[idk_test,:]\n",
    "\n",
    "# Compute the classes within them\n",
    "train_classes_counter = train_data.groupby(by = 'machine_status').count()['sensor_00'].to_dict()\n",
    "test_classes_counter = test_data.groupby(by = 'machine_status').count()['sensor_00'].to_dict()\n",
    "\n",
    "# Remove the classes\n",
    "train_classes = train_data['machine_status']\n",
    "train_data.drop(columns = ['machine_status'], inplace=True)\n",
    "\n",
    "test_classes = test_data['machine_status']\n",
    "test_data.drop(columns = ['machine_status'], inplace=True)\n",
    "\n",
    "# Visualize their dimensions\n",
    "print(\"-\" * 28 + f\"\\nTOTAL: {len(df)} obs. (~ {int(len(df)/1000)} K)\\n\" + \"-\" * 28 + \"\\n\")\n",
    "print( \"-\" * 40 + f\"\\na) TRAIN SUBSET: {len(train_data)} obs. ({(round((len(train_data)/len(df))*100, 1))} %)\\n\"  + \"-\" * 40)\n",
    "print(\"\\t-->\", '\\n\\t--> '.join([f'CLASS \"{class_name}\": {counter} obs. ({(round((counter/len(train_data))*100, 1))} %)'\n",
    "                           for class_name, counter in train_classes_counter.items()]))\n",
    "print(\"\\n\" + \"-\" * 40 + f\"\\nb) TEST SUBSTET:  {len(test_data)} obs. ({(round((len(test_data)/len(df))*100, 1))} %)\\n\"  + \"-\" * 40)\n",
    "print(\"\\t-->\", '\\n\\t--> '.join([f'CLASS {class_name}: {counter} obs. ({(round((counter/len(test_data))*100, 1))} %)'\n",
    "                           for class_name, counter in test_classes_counter.items()]))\n",
    "\n",
    "# METRICHE: Test\n",
    "# precision --> \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data pre-processing\n",
    "**SOURCE**: *'Fault Prediction and Early-Detection in Large PV Power Plants\n",
    "Based on Self-Organizing Maps'* by Alessandro Betti et al. (2021).\n",
    "- Compute a missing feature (i.e., DC Power)\n",
    "- *Data Pre-Processing* (Section 2.3)\n",
    "- *Data Detrending* (Section 2.5)\n",
    "- Data Scaling* (Section 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_processing_steps = {\n",
    "    \"Compute DC Power\": False, \n",
    "    \"Three-phase average\": False,\n",
    "    \"Above Solar Irradiance Minimum\": False,\n",
    "    \"Linear regression for AC power outliers\": False,\n",
    "    \"Linear regression for AC power outliers (Test set)\": False,\n",
    "    \"Data detrending\": False,\n",
    "    \"Data standardization\": True\n",
    "}\n",
    "print(\"\\n\".join([\"PRE-PROCESSING STEP SELECTED: \" + str(step) \n",
    "                     for step, flag in pre_processing_steps.items() if flag == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if pre_processing_steps[\"Data standardization\"]:\n",
    "\n",
    "    # StandardScaler\n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "\n",
    "    # Transform the TRAIN data\n",
    "    train_data = pd.DataFrame(data = scaler.transform(train_data),\n",
    "                                        index = train_data.index, \n",
    "                                        columns = train_data.columns)\n",
    "    print(\"(TRAIN) has been standardized.\")\n",
    "\n",
    "    # Transform the TEST data\n",
    "    test_data = pd.DataFrame(data = scaler.transform(test_data),\n",
    "                                       index = test_data.index, \n",
    "                                       columns = test_data.columns)\n",
    "    print(\" (TEST) has been standardized (using a fitted StandardScaler).\\n\")\n",
    "else:\n",
    "    print(\"This pre-processing step (Data standardization) has not been selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the pre-processing steps \n",
    "### Example of the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-\" * 20 + \" TRAIN \" + \"-\" * 20 )\n",
    "train_data.info()\n",
    "print(\"\\n\" + \"-\" * 20 + \" TEST \" + \"-\" * 20 )\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-organizing map (SOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = {'INV1': train_data}\n",
    "test_data = {'INV1': test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_steps = \"_1hour_averaged_fullReg_detrended\" \n",
    "if system_name == \"Soleto 1\":\n",
    "    trained_version = {\n",
    "        \"INV1\": \"20grid_3Kepoch_0.001lr_10sigma_gaussianFunc\" + pre_steps,\n",
    "        \"INV2\": \"14grid_10Kepoch_0.001lr_9sigma_gaussianFunc\" + pre_steps,\n",
    "        \"INV3\": \"12grid_3Kepoch_0.001lr_7sigma_gaussianFunc\" + pre_steps,\n",
    "        \"INV4\": \"22grid_2Kepoch_0.01lr_8sigma_gaussianFunc\" + pre_steps\n",
    "    }\n",
    "elif system_name == \"Pump sensor\":\n",
    "      trained_version = {\n",
    "        \"INV1\": \"20grid_3Kepoch_0.001lr_10sigma_gaussianFunc\" + pre_steps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(trained_version) if pre_trained else print(f\"PRE TRAINED SOM: {pre_trained}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST AVERAGED SOMs\n",
    "- **Soleto 1**: *18grid_4Kepoch_0.001lr_9sigma_gaussianFunc*\n",
    "    - (INV1:TOP2) --> *18grid_4Kepoch_0.001lr_8sigma_gaussianFunc*\n",
    "- **Soleto 2**: *16grid_4Kepoch_0.001lr_10sigma_gaussianFunc* \n",
    "- **Galatina**: *26grid_10Kepoch_0.01lr_10sigma_gaussianFunc*\n",
    "- **All PV Systems**: *16grid_5Kepoch_0.001lr_9sigma_gaussianFunc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a saving folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------- MAIN FOLDER ----------------\n",
    "saving_folder_name = \"SOMs\"\n",
    "# -------- SUB FOLDERS ----------------\n",
    "saving_graph_folder_name = \"Graphs\"\n",
    "saving_som_folder_name = \"Trained SOM\"\n",
    "saving_kpi_folder_name = \"KPI scores\"\n",
    "saving_warnings_folder_name = \"Warnings\"\n",
    "saving_metrics_folder_name = \"Metrics\"\n",
    "saving_params_folder_name = \"Params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main saving folder\n",
    "saving_folder_path = path.join(system_path, saving_folder_name)\n",
    "\n",
    "# Create the saving folder\n",
    "if not path.exists(saving_folder_path):\n",
    "    makedirs(saving_folder_path) \n",
    "    print(f\"PV System --> {system_name.upper()}\\nA new saving folder has been created: {saving_folder_path}\\n\")\n",
    "\n",
    "# Create the subfolders\n",
    "subfolders = [saving_graph_folder_name, saving_som_folder_name, saving_kpi_folder_name, saving_warnings_folder_name, \n",
    "              saving_metrics_folder_name]\n",
    "\n",
    "for subfolder in subfolders + [saving_params_folder_name]:\n",
    "    subfolder_path = path.join(saving_folder_path, subfolder)\n",
    "    if not path.exists(subfolder_path):\n",
    "        makedirs(subfolder_path)\n",
    "        print(f\"{system_name} --> Folder '{subfolder}' has been created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_topology = 'hexagonal'\n",
    "activation_distance = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "som_config = {\n",
    "    \"INV1\": {\n",
    "        \"dim_grid\": 20,\n",
    "        \"epoch\": 10 * (10**3),\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"sigma\": 2,\n",
    "        \"neighborhood_function\": \"gaussian\"  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_shuffling = True\n",
    "merge_inv_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inv_names = ['INV1']\n",
    "dataset_name = 'all data' \n",
    "\n",
    "trained_som = dict()\n",
    "som_version = dict()\n",
    "\n",
    "for inv_name in inv_names:\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # LOADED SPECIFIC PRETRAINED VERSION\n",
    "    tmp_inv_number = 1\n",
    "    tmp_inv_name = 'INV'+ str(tmp_inv_number)\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # Saving path\n",
    "    file_name = f\"trained_som_{tmp_inv_name}.p\"\n",
    "    loading_path = path.join(saving_folder_path, saving_som_folder_name, trained_version[tmp_inv_name], file_name)\n",
    "\n",
    "    # CASE 1: Load the trained SOM \n",
    "    if pre_trained & path.exists(loading_path):      \n",
    "        with open(loading_path, 'rb') as infile:\n",
    "            som = pickle.load(infile)\n",
    "            print(40 * \"-\", f\"\\nThe trained SOM has been LOADED!\\nVersion [{tmp_inv_name}]: \"\\\n",
    "                  f\"{trained_version[tmp_inv_name]}\\n\" + 40 * \"-\")\n",
    "\n",
    "        # CREATE THE POTENTIAL MSSING SUBFOLDERS for this SOM configuration\n",
    "        pretrained_config_params = trained_version[tmp_inv_name]\n",
    "        pretrained_config_params += \"_trainedInv\" + str(tmp_inv_number) + \"Data\"\n",
    "        trained_som_version = utils.create_somVersion_folders(saving_folder_path, subfolders, dataset_name, \n",
    "                                                              pretrained_config_params, merge_inv_data, \n",
    "                                                              pre_processing_steps)\n",
    "    else:\n",
    "        # CASE 2: Train a SOM\n",
    "\n",
    "        # 0) Merging the inveretr data in case the flag has been set to true\n",
    "        if merge_inv_data:\n",
    "            all_data = [train_data[inv_name] for inv_name in inv_names]\n",
    "            input_data = pd.concat(all_data).sort_index()\n",
    "            print(f\"The inverter data ({len(inv_names)}) has been merged ({len(input_data)} obs.)\")\n",
    "        else: \n",
    "            input_data = train_data[inv_name]\n",
    "\n",
    "        # 0) Create a matrix for the training data\n",
    "        print(\"\\n\" + 50 * \"-\" + \"\\nCreating a data matrix for the training data...\\n\" + 50 * \"-\")\n",
    "        train_matrix, train_cols, train_timestamps = utils.to_num_matrix(input_data, stat_nan_values = \"last_valid_obs\")\n",
    "\n",
    "        # CASE 2.1: Carry out a GRID SEARCH function to find out the optimal hyperparameters\n",
    "        if grid_search:\n",
    "            neighborhood_functions = [\"gaussian\"]\n",
    "\n",
    "            # Grid of values (1540 configs: 14 epoches * 11 grid dims * 10 sigma values)\n",
    "            epoch_values = list(range(500, 10000, 1000)) + list(range(10000, 60000, 10000)) \n",
    "            dim_grid_values = np.arange(4, 32, step = 2)\n",
    "            sigma_values = np.arange(1, 11, step = 1, dtype = np.int32)\n",
    "            learning_rate_values = [0.01, 0.001]\n",
    "\n",
    "            # 2.1.0) Create a base saving folder \n",
    "            path_folder = path.join(saving_folder_path, saving_som_folder_name)\n",
    "\n",
    "            # 2.1.1) TEST DATA: Create a numerical matrix  for the test data\n",
    "            print(\"\\n\" + 50 * \"-\" + \"\\nCreating a data matrix for the test data...\\n\" + 50 * \"-\")\n",
    "            test_matrix, test_cols, test_timestamps = utils.to_num_matrix(test_data[inv_name], stat_nan_values = \"last_valid_obs\")\n",
    "\n",
    "            # Create a compact version of the parameters\n",
    "            params = [epoch_values, dim_grid_values, learning_rate_values, sigma_values, neighborhood_functions]\n",
    "            inv_test_obs_to_ignore = None \n",
    "\n",
    "            # Create the string to save the configuration of the grid search (VAR: dataset type, regression on the test set)\n",
    "            config_type = dataset_name.replace(\"-\", \"\").replace(\" \", \"_\")[:-9]\n",
    "            if pre_processing_steps[\"Linear regression for AC power outliers\"]:\n",
    "                if pre_processing_steps[\"Linear regression for AC power outliers (Test set)\"]:\n",
    "                    config_type += \"_\" + \"fullReg\"\n",
    "                else:\n",
    "                    config_type += \"_\" + \"reg\"\n",
    "            if pre_processing_steps[\"Data detrending\"]:\n",
    "                config_type += \"_\" + \"detrended\"\n",
    "            \n",
    "            fault_df = failure_events['machine_status']#.to_dict()  \n",
    "\n",
    "            # 2.1.2) Start the Grid search to find the optimal parameters\n",
    "            best_som, best_config = utils.grid_search(inv_name, train_matrix, train_timestamps, test_matrix, \n",
    "                                                      test_timestamps, inv_test_obs_to_ignore, params,\n",
    "                                                      map_topology, activation_distance, path_folder, fault_df, config_type,\n",
    "                                                      shuffling_flag = train_data_shuffling, \n",
    "                                                      verbose = True)\n",
    "            trained_som_version = best_config\n",
    "            som = best_som\n",
    "        else:\n",
    "            # CASE 2.2: Train the SOM with the \"static\" hyperparameters\n",
    "            params = som_config[inv_name]\n",
    "            som,  quantization_error, weights = utils.train_som(train_matrix, params[\"dim_grid\"], params[\"epoch\"], \n",
    "                                                                params[\"learning_rate\"], params[\"sigma\"], \n",
    "                                                                map_topology, params[\"neighborhood_function\"], \n",
    "                                                                activation_distance, \n",
    "                                                                shuffling_flag = train_data_shuffling, \n",
    "                                                                verbose = False)\n",
    "\n",
    "            # CREATE THE SUBFOLDERS for this SOM configuration\n",
    "            #pre_processing_steps[\"extra_param\"] = \"run5_shuffling_noSeed\"\n",
    "            trained_som_version = utils.create_somVersion_folders(saving_folder_path, subfolders, dataset_name, params,\n",
    "                                                                  merge_inv_data, pre_processing_steps)\n",
    "\n",
    "        # CASE 2.2.A) Save the pretrained SOM as a file\n",
    "        if merge_inv_data:\n",
    "            file_name = f\"trained_som_mergedInvData.p\"\n",
    "        else:\n",
    "            file_name = f\"trained_som_{inv_name}.p\"\n",
    "        saving_path = path.join(saving_folder_path, saving_som_folder_name, trained_som_version, file_name)\n",
    "        with open(saving_path, 'wb') as outfile:\n",
    "            pickle.dump(som, outfile)\n",
    "            print(\"\\n\"+ 120*\"-\" + f\"\\n\\tThe trained SOM has been SAVED as '{trained_som_version}'.\\n\" + 120*\"-\")\n",
    "\n",
    "        # CASE 2.2.B) Save also the second best SOM [ONLY FOR GRID SEARCH]\n",
    "        #if grid_search and (second_best_config is not None):\n",
    "            #saving_path = path.join(saving_folder_path, saving_som_folder_name, second_best_config, file_name)\n",
    "            #with open(saving_path, 'wb') as outfile:\n",
    "                # pickle.dump(second_best_som, outfile)\n",
    "                # print(\"\\n\"+ 100*\"-\" + f\"\\n\\t\\t\\tThe second best trained SOM has been SAVED as \"\\\n",
    "                      #f\"'{second_best_config}'.\\n\" + 100*\"-\")\n",
    "\n",
    "    # Save the trained SOM for each inverter\n",
    "    trained_som[inv_name] = som\n",
    "    som_version[inv_name] = trained_som_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the KPI scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select period of the sliding window [hours]\n",
    "'None' for computing a *daily KPI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sliding_window = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the KPI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_kpi_scores = False #pre_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpi_scores_inv = dict()\n",
    "thresholds_inv = dict()\n",
    "for inv_name in inv_names:\n",
    "    print(40 * \"-\", inv_name, 40 * \"-\")\n",
    "    \n",
    "    # Load the trained SOM for this inverter\n",
    "    som = trained_som[inv_name]\n",
    "    \n",
    "    train_df = train_data[inv_name]\n",
    "    test_df = test_data[inv_name]\n",
    "    \n",
    "    # Saving paths\n",
    "    kpi_file_name = f\"KPI_scores_{inv_name}.csv\"\n",
    "    threshold_file_name = f\"thresholds_{inv_name}.csv\"\n",
    "    loading_kpi_path = path.join(saving_folder_path, saving_kpi_folder_name, trained_version[inv_name], kpi_file_name)\n",
    "    loading_threshold_path = path.join(saving_folder_path, saving_kpi_folder_name, trained_version[inv_name], \n",
    "                                       threshold_file_name)\n",
    "    \n",
    "    # Load the KPI scores in the case they have already been computed previously\n",
    "    if load_kpi_scores & path.exists(loading_kpi_path):\n",
    "        print(50 * \"-\" + f\"\\nLoading the pre-computed KPI scores/thresholds...\"\\\n",
    "              f\"\\nVersion: {trained_version[inv_name]}\\n\" + 50 * \"-\")\n",
    "        \n",
    "        # Load thresholds\n",
    "        thresholds_df = pd.read_csv(loading_threshold_path)\n",
    "        threshold1 = thresholds_df.iloc[0, 1]\n",
    "        threshold2 = thresholds_df.iloc[1, 1]\n",
    "        thresholds_inv[inv_name] = (threshold1, threshold2)\n",
    "        print(f\"FORMULA: {thresholds_df.iloc[0, 0]} --> THRESHOLD 1: {round(threshold1, 4)}\")\n",
    "        print(f\"FORMULA: {thresholds_df.iloc[1, 0]} --> THRESHOLD 2: {round(threshold2, 4)}\")\n",
    "\n",
    "        # Load the kpi score\n",
    "        kpi_scores_inv[inv_name] = pd.read_csv(loading_kpi_path, index_col=[0]) \n",
    "    else:\n",
    "        # TRAIN DATA: Create a numerical matrix\n",
    "        print(\"\\n\" + 50 * \"-\" + \"\\nCreating a data matrix for the training data...\\n\" + 50 * \"-\")\n",
    "        train_matrix, train_cols, train_timestamps = utils.to_num_matrix(train_df, stat_nan_values = \"last_valid_obs\")\n",
    "\n",
    "        # TEST DATA: Create a numerical matrix \n",
    "        print(\"\\n\" + 50 * \"-\" + \"\\nCreating a data matrix for the test data...\\n\" + 50 * \"-\")\n",
    "        test_matrix, test_cols, test_timestamps = utils.to_num_matrix(test_df, stat_nan_values = \"last_valid_obs\")\n",
    "    \n",
    "        # Computing the KPI scores \n",
    "        std_multipliers = [0.5, 1]\n",
    "        graphs_saving_folder = path.join(saving_folder_path, saving_graph_folder_name, som_version[inv_name]) \n",
    "        kpi_scores, thresholds = utils.compute_kpi_scores(som, inv_name, train_matrix, train_timestamps, \n",
    "                                                          test_matrix, test_timestamps, \n",
    "                                                          std_multipliers, sliding_window, \n",
    "                                                          graphs_saving_folder, visualize_graphs = True)\n",
    "        thresholds_inv[inv_name] = thresholds\n",
    "        kpi_scores_inv[inv_name] = kpi_scores\n",
    "        \n",
    "        # A) Save the thresholds as a CSV file\n",
    "        saving_threhsold_path = path.join(saving_folder_path, saving_kpi_folder_name, som_version[inv_name], threshold_file_name)\n",
    "        with open(saving_threhsold_path, 'w+', encoding=\"utf-8\") as csv_file:\n",
    "            write = csv.writer(csv_file)\n",
    "            write.writerow([\"Formula\", \"Threshold value\"])\n",
    "            write.writerows([\n",
    "                    [f\"(μ - {std_multipliers[0]}σ)\", thresholds[0]],\n",
    "                    [f\"(μ - {std_multipliers[1]}σ)\", thresholds[1]]\n",
    "                ])\n",
    "           \n",
    "        # B) Save the KPI scores as a CSV file\n",
    "        saving_kpi_path = path.join(saving_folder_path, saving_kpi_folder_name, som_version[inv_name], kpi_file_name)\n",
    "        kpi_scores_inv[inv_name].to_csv(saving_kpi_path)\n",
    "        \n",
    "    # Visualize the KPI scores for this inverter\n",
    "    display(kpi_scores_inv[inv_name])\n",
    "    \n",
    "# Visualize all the thresholds  \n",
    "print(50 * \"-\" + \"\\n\\t\\t    THERSHOLDS\\n\" + 50 * \"-\")\n",
    "display(thresholds_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warnings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "1. **Numerical thresholds**;\n",
    "2. **Derivative**: Consider only KPI scores thaving a degradation behaviour (i.e., negative derivative);\n",
    "3. **Persistence**: Increase (+1) the *warning level* in case the KPI score persists for more than once timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the warnings with their relative warning levels [1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inv_warnings = dict()\n",
    "for inv_name in inv_names:\n",
    "    print(50 * \"-\", inv_name, 50 * \"-\")\n",
    "    \n",
    "    # Retrieve potential test observations that should be ignore\n",
    "    inv_obs_to_ignore = None \n",
    "   \n",
    "    # Retrieve the warnings according to thier KPI scores\n",
    "    inv_warnings[inv_name] = utils.create_warning(kpi_scores_inv[inv_name], thresholds_inv[inv_name], inv_obs_to_ignore)\n",
    "    display(inv_warnings[inv_name])\n",
    "    \n",
    "    # Save them in a CSV file\n",
    "    warnings_file_name = f\"{inv_name}_warnings.csv\"\n",
    "    if pre_trained:\n",
    "        warning_subfolder = trained_version[inv_name]\n",
    "    else:\n",
    "        warning_subfolder = som_version[inv_name]\n",
    "    inv_warnings[inv_name].to_csv(path.join(saving_folder_path, saving_warnings_folder_name, warning_subfolder, \n",
    "                                            warnings_file_name))\n",
    "    print(f\"The ({len(inv_warnings[inv_name])}) warnings have been saved in a CSV file.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the correct and wrong predictions (TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create different fault profiles to compute the metrics with different granulairty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_windows = [1, 2, 3, 4, 5, 6, 7]\n",
    "warning_levels = [4, 3, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warning_metrics = dict()\n",
    "for inv_name in inv_names:\n",
    "    \n",
    "    timestamps = kpi_scores_inv[inv_name].index.tolist()\n",
    "    warnings = inv_warnings[inv_name]\n",
    "    \n",
    "    # Initialize the dictionary\n",
    "    warning_metrics[inv_name] = []\n",
    "    \n",
    "    # Compute the metrics for each fault profile\n",
    "    for warning_level in warning_levels:\n",
    "        for prediction_window in prediction_windows:\n",
    "            print(f\"\\nPREDICTION WINDOW: - {prediction_window} days || WARNING LEVELS: >= {warning_level}\")\n",
    "            \n",
    "            # Select the warnings within the warning level selected\n",
    "            selected_warnings = warnings[warnings[\"Warning level\"] >= warning_level]\n",
    "            \n",
    "            # List of failure events\n",
    "            failure_events_list = failure_events['machine_status'].to_dict()  \n",
    "            display(failure_events_list)\n",
    "            \n",
    "            # Compute the metrics\n",
    "            config_metrics = utils.compute_correct_wrong_predictions(timestamps, failure_events_list, selected_warnings.index, \n",
    "                                                                     prediction_window, verbose=True)\n",
    "            \n",
    "            # Save the outcomes\n",
    "            warning_metrics[inv_name].append({\n",
    "                    \"fault_profile\" : \"All\",\n",
    "                    \"faults\": failure_events_list.keys(),\n",
    "                    \"warning_levels\": warning_level,\n",
    "                    \"prediction_window\": prediction_window,\n",
    "                    \"fault_warnings\": selected_warnings.index,\n",
    "                    \"first_warning\": selected_warnings.index[0],\n",
    "                    \"metrics\": list(zip(['TP', 'TN', 'FP', 'FN'], config_metrics)),\n",
    "                })\n",
    "\n",
    "    all_metrics = pd.DataFrame(warning_metrics[inv_name])\n",
    "    print(50 * \"-\" +  f\" {inv_name}: METRICS \" + 50 * \"-\")\n",
    "    display(all_metrics)\n",
    "    print(80 * \"-\")          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the overall metrics\n",
    "1. ** F1-Score**\n",
    "2. **Recall/Hit rate** (correct positive prevision / Retrieve true positive cases)\n",
    "3. **Miss Rate** (a.k.a., FNR: False Negative Rate = FN/TP+FN)\n",
    "4. **Fall-out** (a.k.a., FPR: False Positive Rate = FP/TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_trained = False # ONLY FOR TESTING MIX PRETRAINED SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for inv_name in inv_names:\n",
    "    print(\"\\n\" + 120 * \"-\" + f\"\\n\\t\\t\\t\\t\\t{inv_name}: Analysis of its warning and fault events\\n\" + 120 * \"-\")\n",
    "    \n",
    "    all_metrics = warning_metrics[inv_name]\n",
    "    \n",
    "    # Compute the metrics for each configuration\n",
    "    performances = []\n",
    "    for idk, config in enumerate(all_metrics):\n",
    "        print(40 * \"-\" + f\" CONFIGURATION {idk + 1}/{len(all_metrics)} \" + 30 * \"-\" )\n",
    "        print(f\"WARNING LEVELS: <= {config['warning_levels']}\\nPREDICTION WINDOW: - {config['prediction_window']} day(s)\")\n",
    "        print(f\"FAULT PROFILE: {config['fault_profile']}\\n\"+ 80 * \"-\")\n",
    "        print(80 * \"-\")\n",
    "        \n",
    "        # Retrieve the values of TP, TN, FP, FN\n",
    "        config_metrics = [value for name, value in config[\"metrics\"]]\n",
    "        true_positive, true_negative, false_positive, false_negative = config_metrics\n",
    "        \n",
    "        # Compute the metrics (i.e., recall, ...)\n",
    "        recall, miss_rate, fall_out, precision, f1_score = utils.compute_metrics(true_positive, false_positive, \n",
    "                                                                                 false_negative, true_negative, \n",
    "                                                                                 verbose = True)\n",
    "        # Create a Pandas Series for this metrics\n",
    "        data = (config[\"fault_profile\"], len(config['faults']), config['faults'], \n",
    "                config['warning_levels'], config['prediction_window'], \n",
    "                config[\"first_warning\"], config[\"fault_warnings\"],\n",
    "                f1_score, recall, miss_rate, fall_out, precision)\n",
    "        \n",
    "        column_names = [\"Fault Profile\", \"Num Faults\", \"Faults\", \"Warning levels (>=)\" , \"Prediction Window (days)\",\n",
    "                        \"First Fault Warning\", \"Fault warnings\", \n",
    "                        \"F1 score\", \"Recall\", \"Miss rate\", \"Fall out\", \"Precision\"]\n",
    "        performances.append(pd.Series(data, index = column_names))\n",
    "     \n",
    "    # Create a Pandas Dataframe for the performance of all the fault profiles\n",
    "    metrics_df = pd.DataFrame(performances)\n",
    "    print(\"\\n\"+ \"-\"*40 + f\" SOM PERFORMANCE: {inv_name} \" + 40 * \"-\")\n",
    "    display(metrics_df)\n",
    "    \n",
    "    # Save the metrics\n",
    "    if pre_trained:\n",
    "        subfolder = trained_version[inv_name] + pretrained_config_params\n",
    "    else:\n",
    "        subfolder = som_version[inv_name]\n",
    "        \n",
    "    file_name = f\"{inv_name}_performance.csv\"\n",
    "    file_path = path.join(saving_folder_path, saving_metrics_folder_name, subfolder)\n",
    "    metrics_df.to_csv(path.join(file_path, file_name))\n",
    "    print(f\"The perfomances for all the combinations (i.e., fault profiles, warning levels, time windows) \"\\\n",
    "          f\"\\nhave been saved in '{saving_metrics_folder_name}/{subfolder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cond_warning = metrics_df['Warning levels (>=)'] == 1\n",
    "cond_days = metrics_df['Prediction Window (days)'] == 7\n",
    "\n",
    "display(metrics_df[cond_warning & cond_days])\n",
    "                  \n",
    "# BEST (f1-score): 61%"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sample]",
   "language": "python",
   "name": "conda-env-sample-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
