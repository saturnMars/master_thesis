{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "if '..' not in path:\n",
    "    path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from os import listdir, path\n",
    "from datetime import date\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from _library.utils import SYSTEM_NAMES, SUBFOLDERS, load_datasets\n",
    "import _library.fault_utils as fault_utils\n",
    "from dateutil.parser import ParserError\n",
    "from string import ascii_uppercase\n",
    "from scipy.stats import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/vieri/projects/SAMPLE\n",
      "['Binetto 1', 'Binetto 2', 'Soleto 1', 'Soleto 2', 'Galatina'] \n",
      "\n",
      "['Cleaned', '1-hour sampling', '1-hour averaged sampling', 'Residuals', 'Residuals_analytical', None]\n"
     ]
    }
   ],
   "source": [
    "# Folder path\n",
    "%cd /mnt/data/vieri/projects/SAMPLE/\n",
    "\n",
    "# Visualize names of PV systems\n",
    "print(SYSTEM_NAMES, \"\\n\")\n",
    "print(SUBFOLDERS)\n",
    "# --- 0 ---------- 1 --------- 2 ------ 3 ------ 4 --------- 5 --------- 6 -------- 7 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "system_name = SYSTEM_NAMES[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\t\t\t\tPV SYSTEM --> GALATINA \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Loading inverter data...\n",
      "GALATINA: OK, component data loaded (4) --> INV1, INV2, INV3, INV4\n",
      "\n",
      "Loading irradiance values...\n",
      "GALATINA: OK, raw irradiance data (234226 observations) have been loaded\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "FINISHED!: All datasets have been loaded. (SYS: 4 - IRR FILE: 1)\n",
      "--------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------- \n",
      "EXAMPLE --> Galatina: INV1 (FROM '2016-05-02' TO '2021-06-30': 1885 days).\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99396 entries, 0 to 99395\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Date/Time            99396 non-null  datetime64[ns]\n",
      " 1   Iac R (A)            99396 non-null  int64         \n",
      " 2   Iac S (A)            99396 non-null  int64         \n",
      " 3   Iac T (A)            99396 non-null  int64         \n",
      " 4   Vac R (V)            99396 non-null  int64         \n",
      " 5   Vac S (V)            99396 non-null  int64         \n",
      " 6   Vac T (V)            99396 non-null  int64         \n",
      " 7   Pac R (kW)           99396 non-null  int64         \n",
      " 8   E. totale (kWh)      99396 non-null  float64       \n",
      " 9   Cc 1 (A)             99396 non-null  int64         \n",
      " 10  Vcc 1 (V)            99396 non-null  int64         \n",
      " 11  Allarme              99396 non-null  string        \n",
      " 12  Inverter temp. (°C)  99396 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(10), string(1)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "subfolder = \"Cleaned\"\n",
    "folder_path, inv_data, inv_names, raw_irr_data, string_inv_data, string_inv_names = load_datasets(system_name, \n",
    "                                                                                                  verbose=True,\n",
    "                                                                                                  subfolder = subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_main = inv_data[inv_names[0]]\n",
    "df = string_inv_data[string_inv_names[52]]\n",
    "df.info()\n",
    "display(df)\n",
    "cond_kwh = df[\"Generated Energy (kilowatt-hours)\"] > 1000 #50000\n",
    "cond = df[\"Voltage BN (volts)\"] == 0\n",
    "beyond = df[cond]\n",
    "\n",
    "for idk in beyond.index.tolist():\n",
    "    time_window = 3\n",
    "    neighbourhood = df.iloc[idk - time_window: idk + time_window +1, :]\n",
    "    print(\"IDK: \", idk)\n",
    "    display(neighbourhood)\n",
    "#  2020-07-25 09:05:00\n",
    "#display(df.iloc[114010, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TASK: Numerical comparison between the 'SYSTEM' sheet and the 'SPECIAL STRING INVERTER'\n",
    "\n",
    "# Select the inverters\n",
    "special_stringInv_idk = 52 if system_name == SYSTEM_NAMES[0] else 0\n",
    "system = inv_data[inv_names[0]].copy()\n",
    "string_inverter = string_inv_data[string_inv_names[special_stringInv_idk]].copy()\n",
    "\n",
    "print(system['Generated Power [Average(watts)]'].describe().apply(lambda x: x/1000))\n",
    "\n",
    "# Set the timestamps as index to compare them \n",
    "system.index = system[\"Date/Time [Europe/Rome]\"]\n",
    "system.drop(columns = \"Date/Time [Europe/Rome]\", inplace=True)\n",
    "string_inverter.index = string_inverter[\"Date/Time [Europe/Rome]\"]\n",
    "string_inverter.drop(columns = \"Date/Time [Europe/Rome]\", inplace=True)\n",
    "\n",
    "# Find common columns\n",
    "common_columns = sorted(list(set(system.columns).intersection(string_inverter.columns)), reverse=True)\n",
    "print(f\"\\nCOMMON COLUMNS ({len(common_columns)}/{len(system.columns)}):\\n\", 60*\"-\")\n",
    "print(('\\n').join(common_columns), \"\\n\")\n",
    "\n",
    "period_system = (system.dropna(how=\"all\").index[0].strftime('%Y/%m/%d'), \n",
    "                 system.dropna(how=\"all\").index[-1].strftime('%Y/%m/%d'))\n",
    "period_stringInv = (string_inverter.dropna(how=\"all\").index[0].strftime('%Y/%m/%d'), \n",
    "                    string_inverter.dropna(how=\"all\").index[-1].strftime('%Y/%m/%d'))\n",
    "print(\"PERIODS\\n\", 60*\"-\")\n",
    "print(\"PERIOD (SYSTEM): \\t     \", (\" - \").join(period_system))\n",
    "print(f\"PERIOD (STRING INVERTER {special_stringInv_idk +1}): \", (\" - \").join(period_stringInv))\n",
    "print(\"PERIOD MISSED:  \", pd.to_datetime(period_system[0]) - pd.to_datetime(period_stringInv[0]))\n",
    "print(\"PERIOD AVAILABLE:\", pd.to_datetime(period_stringInv[-1]) - pd.to_datetime(period_stringInv[0]), \"\\n\")\n",
    "\n",
    "similar_columns = []\n",
    "for col in common_columns: \n",
    "    print(\"-\"*10, f\"COLUMN: {col}\", 10*\"-\")\n",
    "    \n",
    "    # Compute the difference \n",
    "    diff = np.abs(system[col] - string_inverter[col])\n",
    "    valid_diff = diff[~diff.isna()]\n",
    "    non_equal = valid_diff[valid_diff > 0]\n",
    "    \n",
    "    # Compute some metrics\n",
    "    mean= np.round(np.mean(valid_diff), 2)\n",
    "    std = np.round(np.std(valid_diff), 2)\n",
    "    \n",
    "    #  Detect whether it could be classified as similar \n",
    "    threshold = 1\n",
    "    are_similar = True if (mean <= threshold and std <= threshold) else False\n",
    "    if are_similar == True:\n",
    "        similar_columns.append(col) \n",
    "    \n",
    "    # Visual output\n",
    "    print(f\"Different observations {len(non_equal)}/{len(valid_diff)} \"\\\n",
    "          f\"({round((len(non_equal)/len(valid_diff))*100, 2) }%) \"\\\n",
    "          f\"with {len(valid_diff) - len(non_equal)} equal obserbations ({round((1 - (len(non_equal)/len(valid_diff)))*100, 2) }%).\")\n",
    "    print(f\"MEAN (abs diff): {mean}\\nSTD (abs diff): {std}\\n\")\n",
    "    \n",
    "    # Example of an observation\n",
    "    random_timestamp = valid_diff.index[randrange(len(valid_diff.index))] \n",
    "    comparison_df = pd.DataFrame(\n",
    "        index = [\"System\", \"String Inverter\", \"Diff\"],\n",
    "        columns = [col.replace(\"[Average\", \"\").rstrip(\"]\")], #.split(\"[\")[0]\n",
    "        data = [\n",
    "            system[col].loc[random_timestamp],\n",
    "            string_inverter[col].loc[random_timestamp],\n",
    "            valid_diff.loc[random_timestamp]\n",
    "        ])\n",
    "    print(\"RANDOM TIMESTAMP:\", random_timestamp)\n",
    "    display(comparison_df.round(decimals=2))\n",
    "    \n",
    "# Visualize the similar columns\n",
    "print(100*\"-\")\n",
    "print(f\"FINDINGS: {len(similar_columns)} COLUMNS THAT SEEM SIMILAR (absolute diff. <= 1 & std. <= 1):\")\n",
    "print((\"\\n\").join(similar_columns))\n",
    "\n",
    "# watt --> kwatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TASK: Calcola valore teorico della potenza AC\n",
    "dc_power_col= \"DC Gen. Power [Average(watts)]\"\n",
    "ac_power_col = \"Generated Power [Average(watts)]\"\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# FORMULA: Watt (W) = Voltage (V) * Ampere (A)\n",
    "\n",
    "# Compute DC current\n",
    "# FORMULA: Ampere (A) = Watt (W) / Voltage (A)\n",
    "cols = [dc_power_col] + ['DC Voltage [Average(volts)]'] \n",
    "computed_dc_current = inv_data[inv_names[0]][ac_cols[0]] / inv_data[inv_names[0]][ac_cols[1]]\n",
    "inv_data[inv_names[0]][\"computed_dc_current [A = W/V]\"] = computed_dc_current\n",
    "\n",
    "# Compute avg e std\n",
    "tmp = computed_dc_current\n",
    "inf_values = len(tmp[tmp == np.inf])\n",
    "tmp[tmp == np.inf] = np.nan\n",
    "tmp = tmp.dropna()\n",
    "print(\"MEAN:\", np.round(np.mean(tmp), 2), \"STD: \", np.round(np.std(tmp), 2))\n",
    "print(f\"INF value discarted: {inf_values} ({round((inf_values / len(computed_dc_current))*100, 2)} %)\")\n",
    "\n",
    "# AC POWER\n",
    "ac_cols = [\"Voltage [Average(volts)]\", \"Current [Average(amps)]\"]\n",
    "computed_ac_power = np.round(inv_data[inv_names[0]][ac_cols[0]] * (inv_data[inv_names[0]][ac_cols[1]] * 77), 1)\n",
    "inv_data[inv_names[0]][\"computed_ac_power [Watts: V*A]\"] = computed_ac_power\n",
    "\n",
    "# VISUALIZE\n",
    "cols = ['Date/Time [Europe/Rome]'] + ac_cols + [ac_power_col] + [\"computed_ac_power [Watts: V*A]\"] + [dc_power_col] \n",
    "new_df = inv_data[inv_names[0]][cols].dropna()\n",
    "print(20 * \"-\", \"AC POWER (data vs computed values)\", 20 * \"-\")\n",
    "display(new_df.iloc[300:400, :])\n",
    "\n",
    "cols = ['Date/Time [Europe/Rome]'] + ['DC Voltage [Average(volts)]'] + [\"computed_dc_current [A = W/V]\"] +[dc_power_col]\n",
    "new_df = inv_data[inv_names[0]][cols].dropna()\n",
    "print(20 * \"-\", \"DC CURRENT (computed values)\", 20 * \"-\")\n",
    "display(new_df.iloc[100:200, :])\n",
    "\n",
    "# Test formula \n",
    "cols = [\"DC Voltage [Average(volts)]\", \"DC Current [Average(amps)]\",\"DC Current [Average(amps).1]\", \"Generated Power [Average(watts)]\", ] #\n",
    "wape_list = []\n",
    "str_inv = string_inv_names[5]\n",
    "x = string_inv_data[str_inv].dropna()\n",
    "\n",
    "#(W = V * A)\n",
    "voltage = x[cols[0]]\n",
    "current = x[cols[1]] + x[cols[2]] # i due gruppi di coppie di stringhe --> le correnti si sommano\n",
    "power = voltage * current \n",
    "x[\"computed_power (W = V*A)\"] = np.round(formula, 1)\n",
    "x[\"delta\"] = np.abs(x[cols[3]] - x[\"computed_power (W = V*A)\"])\n",
    "wape = (np.sum(x[\"delta\"]) / np.sum(x[cols[3]])) * 100\n",
    "wape_list.append(wape)\n",
    "\n",
    "# Visualize\n",
    "cols = ['Date/Time [Europe/Rome]'] + cols + [\"computed_power (W = V*A)\"] + [\"delta\"]\n",
    "display(x[cols].iloc[:500, :])\n",
    "print(f\"WAPE: {np.round(wape)} %\") \n",
    "print(\"WAPE (AVG)\", np.mean(wape_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = inv_data[inv_names[0]]\n",
    "display(df.describe()[\"Vcc 1 (V)\"])\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# FILTER\n",
    "cond = df[\"Vcc 1 (V)\"] < 300\n",
    "filtered = df[cond][[\"Date/Time\", \"Vcc 1 (V)\"]]\n",
    "display(filtered.iloc[:500, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "df = inv_data[inv_names[0]]\n",
    "\n",
    "# Problematic obs\n",
    "df[\"delta\"] = [delta.components[1] if not pd.isnull(delta) else 0 for delta in df[\"Date/Time\"].diff()]\n",
    "cond1 = df[\"delta\"] > 1\n",
    "cond2 = df[\"Date/Time\"].dt.time > pd.to_datetime(\"07:00\").time()\n",
    "problematic_obs = df[cond1 & cond2]\n",
    "#df.drop(columns=\"delta\", inplace=True)\n",
    "print(\"Problematic observations:\", len(problematic_obs), f\"({round((len(problematic_obs)/len(df))*100, 2)}%)\\n\")\n",
    "display(problematic_obs.iloc[:500, [0, -1]])\n",
    "\n",
    "# Filtered df\n",
    "cond3 = df[\"Irradiance (W/mq)\"] > 1400\n",
    "filtered_df = df[cond1].iloc[:500, :]\n",
    "#display(df[df[\"Date/Time\"].dt.date == pd.to_datetime(\"2019-06-20\").date()])\n",
    "\n",
    "#View all\n",
    "#display(df.iloc[:500, :])\n",
    "df.info()\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = inv_data[inv_names[4]]\n",
    "cond = df[\"Vac R (V)\"] == 0\n",
    "display(df[cond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute difference between temperatures\n",
    "to_load = inv_names[0]\n",
    "x = pd.DataFrame(np.abs(inv_data[to_load][\"Ambient Temp. [Average(celsius)]_SYS\"] - inv_data[to_load][\"Ambient Temp. [Average(celsius)]_AMB\"]))\n",
    "len_pre_x = len(x)\n",
    "x = x.dropna()\n",
    "print(\"NaN values dropped: \", len_pre_x - len(x))\n",
    "\n",
    "# Highlight values with difference\n",
    "diff = x[x.iloc[:, 0] > 0]\n",
    "print(\"Observations with a DIFF:\",len(diff))\n",
    "display(diff)\n",
    "\n",
    "print(\"MEAN: \", np.mean(x)[0])\n",
    "print(\"STD: \", np.std(x)[0])\n",
    "\n",
    "# STATEGY: Keep the one with the most value + join if missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# -------- TASK: Analiza comportamento trifase in un dato giorno ---------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "if (system_name != SYSTEM_NAMES[0]) and (system_name != SYSTEM_NAMES[1]):\n",
    "    df = inv_data[to_load].copy()\n",
    "    pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "    # To filter\n",
    "    column_to_filter = datetime_column_name\n",
    "    day_to_display = date(2020, 9, 1)\n",
    "    cond = df[column_to_filter].dt.date == day_to_display  #.between(\"2020-01-13\", \"2020-01-13\")\n",
    "\n",
    "    # To visualize\n",
    "    column_to_visualize = \"Irradiance [Average(watts-per-meter-sq)]\"\n",
    "    filtered_df = df[cond].iloc[:, :8]\n",
    "    filtered_df[datetime_column_name] = filtered_df[datetime_column_name].dt.strftime(\"%H:%M\")\n",
    "    filtered_df.rename(columns = {datetime_column_name: \"Time\"}, inplace=True)\n",
    "\n",
    "    # Visual representation\n",
    "    fig, axes = plt.subplots(nrows = 3, figsize=(15, 15))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    fig.suptitle(r\"$\\bf{\" + system_name.upper().replace(' ','\\\\ ') + \"}$: Trifase [\"+ str(day_to_display) +\"]\",\n",
    "                     fontsize=30, color='dimgray', y=0.99) #\n",
    "\n",
    "    sns.scatterplot(data=filtered_df, x=\"Time\", y=\"Iac R (A)\", ax = axes[0], label =\"Iac R\", \n",
    "                    color= \"red\", s = 10, alpha=0.8)\n",
    "    sns.scatterplot(data=filtered_df, x=\"Time\", y=\"Iac S (A)\", ax = axes[0], label =\"Iac S\", \n",
    "                    color= \"orange\",s = 10, alpha=0.8)\n",
    "    sns.scatterplot(data=filtered_df, x=\"Time\", y=\"Iac T (A)\", ax = axes[0], label =\"Iac T\", \n",
    "                    color= \"dodgerblue\", s = 10, alpha=0.8)\n",
    "    axes[0].xaxis.set_major_locator(MaxNLocator(18))\n",
    "    axes[0].set_ylabel(\"Ampere [A]\", fontsize=\"large\", fontweight='bold', labelpad = 10)\n",
    "    axes[0].set_xlabel(\"Time\", fontsize=\"large\", fontweight='bold', labelpad = 5)\n",
    "    axes[0].set_title(\"Correnti\", fontsize=\"xx-large\")\n",
    "    axes[0].tick_params(axis='y', which='major', grid_linestyle = \"-.\", grid_alpha=0.8)\n",
    "\n",
    "    sns.scatterplot(data=filtered_df, x=\"Time\", y=\"Vac R (V)\", ax = axes[1], label =\"Vac R\", \n",
    "                    color= \"red\", s = 10, alpha=0.8)\n",
    "    sns.scatterplot(data=filtered_df, x=\"Time\", y=\"Vac S (V)\", ax = axes[1], label =\"Vac S\", \n",
    "                    color= \"orange\", s = 10, alpha=0.8)\n",
    "    sns.scatterplot(data=filtered_df, x=\"Time\", y=\"Vac T (V)\", ax = axes[1], label =\"Vac T\", \n",
    "                    color= \"dodgerblue\", s = 10,alpha=0.8)\n",
    "    axes[1].xaxis.set_major_locator(MaxNLocator(18))\n",
    "    axes[1].set_ylabel(\"Voltage [V]\", fontsize=\"large\", fontweight='bold', labelpad = 10)\n",
    "    axes[1].set_xlabel(\"Time\", fontsize=\"large\", fontweight='bold', labelpad = 5)\n",
    "    axes[1].set_title(\"Voltaggi\", fontsize=\"xx-large\")\n",
    "    axes[1].tick_params(axis='y', which='major', grid_linestyle = \"-.\", grid_alpha=0.8)\n",
    "\n",
    "    sns.scatterplot(x=filtered_df[\"Time\"], y=filtered_df[\"Pac R (kW)\"] , \n",
    "                    ax = axes[2], label =\"Pac R\", color= \"dodgerblue\")\n",
    "\n",
    "    axes[2].xaxis.set_major_locator(MaxNLocator(18))\n",
    "    axes[2].set_ylabel(\"Power [kW]\", fontsize=\"large\", fontweight='bold', labelpad = 10)\n",
    "    axes[2].set_xlabel(\"Time\", fontsize=\"large\", fontweight='bold', labelpad = 5)\n",
    "    axes[2].set_title(\"AC Power generated\", fontsize=\"xx-large\")\n",
    "    axes[2].tick_params(axis='y', which='major', grid_linestyle = \"-.\", grid_alpha=0.8)\n",
    "\n",
    "    fig.tight_layout(pad = 2)\n",
    "    fig.savefig(folder_path, bbox_inches='tight', pad_inches=1)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"This analysis isn't necessary for this PV system!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_load = inv_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ----------------- TASK: Analizza il comportamento del sampling ---------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "pd.options.display.max_rows = 1000\n",
    "print(50*\"-\"+ \"SYSTEM: \", system_name.upper() + 50*\"-\")\n",
    "\n",
    "# Set the dataset that should be analysed \n",
    "df = inv_data[to_load] \n",
    "#df = raw_irr_data\n",
    "\n",
    "datetime_df = pd.DataFrame()\n",
    "datetime_column_name = df.columns[0]\n",
    "\n",
    "# Extract date and time\n",
    "datetime_df[\"Date\"] = df[datetime_column_name].dt.date\n",
    "datetime_df[\"Time\"] = df[datetime_column_name].dt.time \n",
    "datetime_df[\"SAMPLING TIME\"] = datetime_df[\"Time\"].apply(lambda time: \"Even (XX:X0)\" if time.minute % 2 == 0 else \"Odd XX:X5\")\n",
    "datetime_df[\"SAMPLING [Min]\"] = [delta.seconds//60 if not pd.isnull(delta) else 0 for delta in df[datetime_column_name].diff()]\n",
    "\n",
    "# Compute the changes(i.e., deltas) of irradiance values\n",
    "if df.columns[1] == \"irr. medio 1 W/mq\":\n",
    "    datetime_df[\"Irradiance\"] = df[df.columns[1]]\n",
    "    datetime_df[\"Delta irr\"] = np.absolute(df[df.columns[1]].diff())\n",
    "\n",
    "# Exclude particular types of occurrences\n",
    "# A) Midnight occurrences (00:00)\n",
    "datetime_df = datetime_df[datetime_df[\"Time\"] != pd.to_datetime(\"00:00:00\").time()]\n",
    "\n",
    "# B) First occurence of the day (e.g., 5:00 AM)\n",
    "datetime_df[\"Same day\"] = datetime_df[\"Date\"].diff().apply(lambda diff: True if diff.days == 0 else False)\n",
    "datetime_df = datetime_df[datetime_df[\"Same day\"] == True]\n",
    "datetime_df.drop(columns=[\"Same day\"], inplace=True)\n",
    "\n",
    "# Quick visualization of the unique sampling hours and deltas\n",
    "print(\"UNIQUE SAMPLING HOURS:\", sorted(set(time.hour for time in datetime_df[\"Time\"].tolist())))\n",
    "print(\"UNIQUE DELTA SAMPLING [min]:\\n\", sorted(datetime_df[\"SAMPLING [Min]\"].unique()))\n",
    "\n",
    "# VIEW 1: occurences for each type of the time (XX:X0: even, XX:X5: odd)\n",
    "time_type_counter = datetime_df[[\"Time\",  \"SAMPLING TIME\"]].groupby([\"SAMPLING TIME\"]).count()\n",
    "time_type_counter.rename(columns = {\"Time\": \"Occurrences\"}, inplace=True)\n",
    "print(\"\\nTYPE OF SAMPLING TIMES\")\n",
    "display(time_type_counter)\n",
    "\n",
    "# VIEW 2: Occurences for each type of sampling (e.g. 5, 10, 15 minutes)\n",
    "type_counter = datetime_df[[\"Time\",  \"SAMPLING [Min]\"]].groupby([\"SAMPLING [Min]\"]).count()\n",
    "type_counter.rename(columns = {\"Time\": \"Occurrences\"}, inplace=True)\n",
    "type_counter.sort_values(by=[\"Occurrences\"], ascending=False, inplace=True)\n",
    "print(\"\\nOCCURENCES FOR EACH TYPE\")\n",
    "display(type_counter)\n",
    "print(f\"TOTAL: {len(datetime_df)} (first daily occurrences as well as the occurrence at midnight have been removed)\")\n",
    "\n",
    "# VIEW 3: Daily occurences for each type of sampling (count + mean/std for irradiance values )\n",
    "if \"Irradiance\" in datetime_df.columns: \n",
    "    daily_type_counter = datetime_df[[\"Date\",  \"SAMPLING [Min]\", \"Time\", \"Delta irr\"]]\\\n",
    "    .groupby([\"Date\", \"SAMPLING [Min]\"])\\\n",
    "    .agg(Occurrences = (\"Time\", \"count\"),\n",
    "         Mean_deltaIrr = (\"Delta irr\", np.mean),\n",
    "         Std_deltaIrr= (\"Delta irr\", np.std)\n",
    "        )\n",
    "else:\n",
    "    daily_type_counter = datetime_df[[\"Date\",  \"SAMPLING [Min]\", \"Time\"]]\\\n",
    "    .groupby([\"Date\", \"SAMPLING [Min]\"])\\\n",
    "    .agg(Occurrences = (\"Time\", \"count\"))\n",
    "daily_type_counter = daily_type_counter.round(2)\n",
    "\n",
    "# Extra column 3.1: Compute percentage of the grouped daily occurences\n",
    "daily_occ = datetime_df[[\"Date\", \"Time\"]].groupby([\"Date\"]).count()[\"Time\"]\n",
    "daily_percentages = round((daily_type_counter[\"Occurrences\"] / daily_occ)*100, 1)\n",
    "daily_type_counter.insert(1, \"Percentage [%]\", daily_percentages)\n",
    "print(\"\\nDAILY OCCURRENCES\")\n",
    "display(daily_type_counter.iloc[100:200,:])\n",
    "\n",
    "# VIEW 4: Montly occurences for each type of sampling\n",
    "montly_df = datetime_df[[\"Date\", \"Time\", \"SAMPLING [Min]\"]]\n",
    "montly_df[\"Month\"] = pd.to_datetime(datetime_df[\"Date\"]).dt.to_period('M')\n",
    "\n",
    "month_type_counter = montly_df[[\"Month\", \"Time\", \"SAMPLING [Min]\"]].groupby([\"Month\", \"SAMPLING [Min]\"]).count()\n",
    "month_type_counter.rename(columns = {\"Time\": \"Occurrences\"}, inplace=True)\n",
    "\n",
    "# Extra column 4.1: Compute percentage of the grouped montly occurences\n",
    "montly_occ = montly_df[[\"Month\", \"Time\",]].groupby([\"Month\"]).count()[\"Time\"]\n",
    "month_type_counter[\"Percentage [%]\"] = round((month_type_counter[\"Occurrences\"] / montly_occ)*100, 2)\n",
    "print(\"\\nDAILY OCCURRENCES\")\n",
    "display(month_type_counter.iloc[:100,:])\n",
    "\n",
    "# VIEW 5: Compute the montly behaviour (Nominal VS wrong sampling) \n",
    "# 5.1) Define \"Nominal\" sampling as the most frequent one found out in the previous analysis (VIEW 2) \n",
    "default_sampling_time = type_counter.index.get_level_values('SAMPLING [Min]')[0]\n",
    "is_nominal = lambda sampling_time: \"Yes\" if (sampling_time == default_sampling_time) else \"No\"\n",
    "col_name = f\"Default sampling time selected [{default_sampling_time} mins]\"\n",
    "montly_df[col_name] = montly_df[\"SAMPLING [Min]\"].apply(is_nominal)\n",
    "\n",
    "# 5.2) Group and visualize\n",
    "default_sampling_counter = montly_df[[\"Month\", \"Time\",col_name]].groupby([\"Month\", col_name]).count()\n",
    "default_sampling_counter.rename(columns = {\"Time\": \"Occurrences\"}, inplace=True)\n",
    "default_sampling_counter[\"Percentage [%]\"] = round((default_sampling_counter[\"Occurrences\"] / montly_occ)*100, 1)\n",
    "default_sampling_counter.sort_values(by=[\"Month\", \"Occurrences\"], ascending=[True, False], inplace=True)\n",
    "display(default_sampling_counter)\n",
    "\n",
    "# INSPECTION: Visualize problematic values/dates\n",
    "val_cond = datetime_df[\"SAMPLING [Min]\"] == 0\n",
    "date_cond = datetime_df[\"Date\"].between(date(2019, 5, 3), date(2019, 5, 5)) # == date(2020, 4, 27)\n",
    "display(datetime_df.loc[date_cond,:])\n",
    "\n",
    "# SAVE THE FINDINGS (as a multi-sheet excel file)\n",
    "# Define file name and the saving folder\n",
    "if \"Irradiance\" in datetime_df.columns:\n",
    "    file_name = system_name + \"_Irradiance sampling analysis.xlsx\"\n",
    "else:\n",
    "    file_name = system_name + \" - \"+ to_load.capitalize() +\" - Sampling analysis.xlsx\"\n",
    "saving_folder = path.join(folder_path, \"..\", \"Distribution analyses\")\n",
    "\n",
    "# Excel writer\n",
    "writer = pd.ExcelWriter(path.join(saving_folder, file_name))\n",
    "\n",
    "# Create the different sheets\n",
    "type_counter.to_excel(writer, sheet_name=\"Sampling\")\n",
    "default_sampling_counter.to_excel(writer, sheet_name=\"Monlty nominal behavioir\")\n",
    "daily_type_counter.to_excel(writer, sheet_name=\"Daily sampling\")\n",
    "month_type_counter.to_excel(writer, sheet_name=\"Montly sampling\")\n",
    "time_type_counter.to_excel(writer, sheet_name=\"Time types\")\n",
    "writer.save()\n",
    "\n",
    "print(\"The findings have been saved in: \", saving_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# --------------------- TASK: Analizza possibile colonne uguali  ---------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "df = inv_data[to_load].copy()\n",
    "\n",
    "pairs_to_check = [\n",
    "    (\"Generated Energy [Interval Sum(kilowatt-hours)]\", \"PV Energy [Interval Sum(kilowatt-hours)]\"),\n",
    "    (\"Generated Power [Average(watts)]\", \"PV Power [Average(watts)]\")\n",
    "]\n",
    "\n",
    "for columns in pairs_to_check:    \n",
    "    # Compute absolute difference\n",
    "    df[\"diff\"] = df[columns[0]] - df[columns[1]]\n",
    "    diff = np.absolute(np.array(df[\"diff\"]))\n",
    "    \n",
    "    # Compute mean and standard deviation\n",
    "    mean = np.nanmean(diff)\n",
    "    std = np.nanstd(diff)\n",
    "    \n",
    "    column_names = [col.split(\"[\")[0].rstrip() for col in columns]\n",
    "    print(f\"DELTA: ({column_names[0]} VS {column_names[1]})\")\n",
    "    print(f\"--> MEAN: {mean}\")\n",
    "    print(f\"--> STD:  {std}\\n\")\n",
    "    #display(df[[columns[0], columns[1], \"diff\"]].iloc[4100:4300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# --------------------- TASK: Analizza buchi nei dati  ---------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "df = inv_data[to_load].copy()\n",
    "empty_entries = df[df[\"Current [Average(amps)]\"].isnull()]#[\"Date/Time [Europe/Rome]\"]\n",
    "empty_months = set(empty_entries.iloc[:, 0].dt.to_period('M').astype(str))\n",
    "\n",
    "pd.options.display.max_rows = 10000\n",
    "#print(empty_months)\n",
    "display(empty_entries.iloc[80000:84210, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# String Box alarms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load inverter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "system_name = SYSTEM_NAMES[2]\n",
    "subfolder = \"1-hour averaged sampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\t\t\t\tPV SYSTEM --> SOLETO 1 \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Loading inverter data...\n",
      "SOLETO 1: OK, component data loaded (4) --> INV1, INV2, INV3, INV4\n",
      "-------------------------------------------------------------------------------- \n",
      "FINISHED!: All datasets have been loaded. (SYS: 4 - IRR FILE: 0)\n",
      "--------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------- \n",
      "EXAMPLE --> Soleto 1: INV1 (FROM '2018-08-08' TO '2021-06-30': 1057 days).\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15586 entries, 0 to 15585\n",
      "Data columns (total 20 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   Date/Time                   15586 non-null  datetime64[ns]\n",
      " 1   Iac R (A)                   15586 non-null  int64         \n",
      " 2   Iac S (A)                   15586 non-null  int64         \n",
      " 3   Iac T (A)                   15586 non-null  int64         \n",
      " 4   Vac R (V)                   15586 non-null  int64         \n",
      " 5   Vac S (V)                   15586 non-null  int64         \n",
      " 6   Vac T (V)                   15586 non-null  int64         \n",
      " 7   Pac R (kW)                  15586 non-null  int64         \n",
      " 8   E. totale (kWh)             15586 non-null  float64       \n",
      " 9   Cc 1 (A)                    15586 non-null  int64         \n",
      " 10  Vcc 1 (V)                   15586 non-null  int64         \n",
      " 11  Allarme                     15586 non-null  string        \n",
      " 12  Inverter temp. (°C)         15586 non-null  int64         \n",
      " 13  Irradiance (W/mq)           15586 non-null  int64         \n",
      " 14  Amb. Temp (°C)              15586 non-null  float64       \n",
      " 15  Humidity (%)                15087 non-null  float64       \n",
      " 16  Atmospheric Pressure (hPa)  15585 non-null  float64       \n",
      " 17  Rainfall (mm)               15586 non-null  float64       \n",
      " 18  Wind speed (m/s)            6941 non-null   float64       \n",
      " 19  Wind direction (°)          6958 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(11), string(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "folder_path, inv_data, inv_names, *_, = load_datasets(system_name, verbose=True, subfolder = subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve *failure events* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fault_priorities = [\"High\", \"Medium\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_load = {\n",
    "    'faults': True, \n",
    "    'inv_alarms': False, \n",
    "    'stringBox_alarms': True\n",
    "}\n",
    "include_faults_notRelatedToInverters = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "\t\t\t\t\tFAULTS: Soleto 1\n",
      "\t\t\t\tPRIORITIES: High, Medium & faults\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0) 1 fault(s) called 'scheda di comunicazione' have/has been discarted. As it's not related to inverter operation.\n",
      "\n",
      "0) SELECTING only the string box-related faults\n",
      "\n",
      "--> A) General faults loaded (1)\n",
      "--> [B) Inverter logs have been skipped (0)]\n",
      "--> C) String-box logs loaded (INV1: 31230, INV2: 3055, INV3: 5075, INV4: 1615)\n",
      "\n",
      "Loading completed!\n",
      "\n",
      "FAUL CAUSES (4):\n",
      "--------------------\n",
      "1) Allarme string-box\n",
      "2) Ritardo comunicazione dispositivo\n",
      "3) String-box con produzione anomala\n",
      "4) Unknown\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\t\t\t\t\t\tFAUL EVENTS (period >= 2018-08-08)\n",
      "\t\t\t\t\tPRIORITIES: Log_stringBox - Medium, Log_stringBox - High, General Fault\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inverter</th>\n",
       "      <th>Componente Guasto</th>\n",
       "      <th>Causa Guasto</th>\n",
       "      <th>Inizio</th>\n",
       "      <th>Fine</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CSP3.6 V130086: String-box con produzione anomala</td>\n",
       "      <td>String-box con produzione anomala</td>\n",
       "      <td>2018-08-08 11:51:00</td>\n",
       "      <td>2018-10-18 14:50:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s1: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 13:26:00</td>\n",
       "      <td>2018-08-08 14:52:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>CSP2.6 V180556 s9: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 14:13:00</td>\n",
       "      <td>2018-08-08 14:21:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>CSP2.6 V180556 s9: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 14:33:00</td>\n",
       "      <td>2018-08-08 15:26:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s10: [3] Corrente di stringa fu...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 14:41:00</td>\n",
       "      <td>2018-08-08 14:52:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39915</th>\n",
       "      <td>3</td>\n",
       "      <td>CSP3.6 V130086 s6: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-16 14:32:00</td>\n",
       "      <td>2021-09-16 14:44:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39916</th>\n",
       "      <td>3</td>\n",
       "      <td>CSP3.6 V130086 s6: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-16 15:34:00</td>\n",
       "      <td>2021-09-16 15:40:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39917</th>\n",
       "      <td>3</td>\n",
       "      <td>CSP3.6 V130086 s6: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-16 15:45:00</td>\n",
       "      <td>2021-09-16 15:51:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39918</th>\n",
       "      <td>4</td>\n",
       "      <td>CSP4.6 V180543 s11: [3] Corrente di stringa fu...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-17 08:46:00</td>\n",
       "      <td>2021-09-17 08:52:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39919</th>\n",
       "      <td>4</td>\n",
       "      <td>CSP4.6 V180543 s11: [3] Corrente di stringa fu...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-17 09:42:00</td>\n",
       "      <td>2021-09-17 09:49:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39917 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Inverter                                  Componente Guasto  \\\n",
       "3            3  CSP3.6 V130086: String-box con produzione anomala   \n",
       "4            1  CSP1.6 V180544 s1: [3] Corrente di stringa fuo...   \n",
       "5            2  CSP2.6 V180556 s9: [3] Corrente di stringa fuo...   \n",
       "6            2  CSP2.6 V180556 s9: [3] Corrente di stringa fuo...   \n",
       "7            1  CSP1.6 V180544 s10: [3] Corrente di stringa fu...   \n",
       "...        ...                                                ...   \n",
       "39915        3  CSP3.6 V130086 s6: [3] Corrente di stringa fuo...   \n",
       "39916        3  CSP3.6 V130086 s6: [3] Corrente di stringa fuo...   \n",
       "39917        3  CSP3.6 V130086 s6: [3] Corrente di stringa fuo...   \n",
       "39918        4  CSP4.6 V180543 s11: [3] Corrente di stringa fu...   \n",
       "39919        4  CSP4.6 V180543 s11: [3] Corrente di stringa fu...   \n",
       "\n",
       "                            Causa Guasto              Inizio  \\\n",
       "3      String-box con produzione anomala 2018-08-08 11:51:00   \n",
       "4                     Allarme string-box 2018-08-08 13:26:00   \n",
       "5                     Allarme string-box 2018-08-08 14:13:00   \n",
       "6                     Allarme string-box 2018-08-08 14:33:00   \n",
       "7                     Allarme string-box 2018-08-08 14:41:00   \n",
       "...                                  ...                 ...   \n",
       "39915                 Allarme string-box 2021-09-16 14:32:00   \n",
       "39916                 Allarme string-box 2021-09-16 15:34:00   \n",
       "39917                 Allarme string-box 2021-09-16 15:45:00   \n",
       "39918                 Allarme string-box 2021-09-17 08:46:00   \n",
       "39919                 Allarme string-box 2021-09-17 09:42:00   \n",
       "\n",
       "                      Fine                    Tipo  \n",
       "3      2018-10-18 14:50:00  Log_stringBox - Medium  \n",
       "4      2018-08-08 14:52:00  Log_stringBox - Medium  \n",
       "5      2018-08-08 14:21:00  Log_stringBox - Medium  \n",
       "6      2018-08-08 15:26:00  Log_stringBox - Medium  \n",
       "7      2018-08-08 14:52:00  Log_stringBox - Medium  \n",
       "...                    ...                     ...  \n",
       "39915  2021-09-16 14:44:00  Log_stringBox - Medium  \n",
       "39916  2021-09-16 15:40:00  Log_stringBox - Medium  \n",
       "39917  2021-09-16 15:51:00  Log_stringBox - Medium  \n",
       "39918  2021-09-17 08:52:00  Log_stringBox - Medium  \n",
       "39919  2021-09-17 09:49:00  Log_stringBox - Medium  \n",
       "\n",
       "[39917 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL: 39917 failure events\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\t\t\t\t\tFAULT EVENTS ('General Fault')\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inverter</th>\n",
       "      <th>Componente Guasto</th>\n",
       "      <th>Causa Guasto</th>\n",
       "      <th>Inizio</th>\n",
       "      <th>Fine</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>datexel - scheda PV isolation di un quadro di ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-08 08:39:00</td>\n",
       "      <td>2019-11-08 12:30:00</td>\n",
       "      <td>General Fault</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Inverter                                  Componente Guasto  \\\n",
       "11291     <NA>  datexel - scheda PV isolation di un quadro di ...   \n",
       "\n",
       "      Causa Guasto              Inizio                 Fine           Tipo  \n",
       "11291      Unknown 2019-11-08 08:39:00  2019-11-08 12:30:00  General Fault  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the fault dataset: Storico guasti.xlsx (a.k.a., 'General faults') & PV SYSTEM - Storico Allarme.xlsx (a.k.a., Log - X)\n",
    "fault_df = fault_utils.load_faults(system_name, include_faults_notRelatedToInverters, to_load['inv_alarms'], fault_priorities, \n",
    "                                   to_load['stringBox_alarms'], to_load['faults'], verbose = False)\n",
    "\n",
    "# Isolate the fault in the period covered by the dataset\n",
    "start_dates = [inv_data[inv_name].iloc[0, 0] for inv_name in inv_names]\n",
    "first_start_date = sorted(start_dates)[0]\n",
    "fault_df = fault_df[fault_df[\"Inizio\"] >= first_start_date]\n",
    "\n",
    "print(\"\\n\"+\"-\"* 120 + f\"\\n\\t\\t\\t\\t\\t\\tFAUL EVENTS (period >= {first_start_date.strftime('%Y-%m-%d')})\")\n",
    "print(\"\\t\\t\\t\\t\\tPRIORITIES:\", (', ').join([priority for priority in fault_df['Tipo'].unique()]) \n",
    "      + \"\\n\" + \"-\"* 120)\n",
    "display(fault_df)\n",
    "print(f\"TOTAL: {len(fault_df)} failure events\")\n",
    "\n",
    "# --------------- Isolate only the (general) faults observations ---------------------------------\n",
    "fault_to_vis = \"General Fault\" \n",
    "fault_type_cond = fault_df[\"Tipo\"] == fault_to_vis\n",
    "print(\"\\n\"+\"-\"* 105 + f\"\\n\\t\\t\\t\\t\\tFAULT EVENTS ('{fault_to_vis}')\\n\" + \"-\"* 105)\n",
    "only_fault_df = fault_df[fault_type_cond]\n",
    "if len(only_fault_df) > 0:\n",
    "    display(only_fault_df)\n",
    "else:\n",
    "    print(f\"\\n[{system_name}] No faults available for this PV system.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize alarm frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_timestamps(df_row, hour_to_consider = 'Fine'):\n",
    "    ts_format = '%Y-%m-%d %H'\n",
    "    \n",
    "    try: \n",
    "        hour = pd.to_datetime(df_row[hour_to_consider]).strftime(ts_format)\n",
    "    except ParserError:\n",
    "        hour = pd.to_datetime(df_row['Inizio']).strftime(ts_format)\n",
    "    return pd.to_datetime(hour)\n",
    "\n",
    "def generate_num_matrix(alarm_df, alarm_type, hourly_tolerance = 1):\n",
    "    \n",
    "    # Initizalize the matrix\n",
    "    matrix = np.zeros(shape = len(alarm_df), dtype = int)\n",
    "    \n",
    "    # Isolate the selected alarms\n",
    "    selected_alarms = alarm_df[alarm_df['Tipo'] == alarm_type]\n",
    "    selected_alarms_ts = selected_alarms['Hourly timestamp']\n",
    "    print(f\"SELECTED ALARMS ({len(selected_alarms)}): {alarm_type}\")\n",
    "    \n",
    "    if hourly_tolerance != 0:\n",
    "        for ts in selected_alarms_ts:\n",
    "            \n",
    "            # Select the starting timestamps\n",
    "            starting_ts = ts - pd.Timedelta(hourly_tolerance, unit= 'hours')\n",
    "            \n",
    "            # Retrieve the observations within this tolerance\n",
    "            cond = alarm_df['Hourly timestamp'].between(starting_ts, ts, inclusive = 'left')\n",
    "            alarms_to_add = alarm_df[cond]\n",
    "           \n",
    "            print(\"ts\", ts)\n",
    "            print(\"starting ts\", starting_ts)\n",
    "            display(alarms_to_add)\n",
    "            \n",
    "            if len(alarms_to_add) > 0:\n",
    "                selected_alarms = pd.concat([selected_alarms, alarms_to_add])\n",
    "                display(selected_alarms)\n",
    "\n",
    "    # Set the cell to 1 \n",
    "    for alarm_idk in selected_alarms.index:       \n",
    "        matrix[alarm_idk] = 1\n",
    "\n",
    "    # Check the validity\n",
    "    num_nonZeros = len(np.nonzero(matrix)[0])\n",
    "    assert num_nonZeros == len(selected_alarms), f\"ISSUE, Matrix ones: {num_nonZeros} || ALARMS: {len(selected_alarms)}\"\n",
    "    \n",
    "    # return the computed matrix\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.dates import ConciseDateFormatter, AutoDateFormatter, AutoDateLocator, DateFormatter, DayLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fault_df['Hourly timestamp'] = fault_df.apply(func = lambda df_row: convert_timestamps(df_row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filling_empty_hours = True\n",
    "empty_hours_to_zero = True\n",
    "drop_high_freq_category = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------ INV1 ------------------------------------------------------------\n",
      "\n",
      "----------------------------------- ALARMS OF THE STRING BOXES CONNECTED TO THE INVERTER -----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inverter</th>\n",
       "      <th>Componente Guasto</th>\n",
       "      <th>Causa Guasto</th>\n",
       "      <th>Inizio</th>\n",
       "      <th>Fine</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Hourly timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s1: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 13:26:00</td>\n",
       "      <td>2018-08-08 14:52:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2018-08-08 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s10: [3] Corrente di stringa fu...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 14:41:00</td>\n",
       "      <td>2018-08-08 14:52:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2018-08-08 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s10: [3] Corrente di stringa fu...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 15:01:00</td>\n",
       "      <td>2018-08-08 15:26:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2018-08-08 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s2: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 15:01:00</td>\n",
       "      <td>2018-08-08 15:26:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2018-08-08 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s1: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2018-08-08 15:01:00</td>\n",
       "      <td>2018-08-08 15:12:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2018-08-08 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39900</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s10: [3] Corrente di stringa fu...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-15 16:17:00</td>\n",
       "      <td>2021-09-15 16:31:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2021-09-15 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39901</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s3: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-15 16:17:00</td>\n",
       "      <td>2021-09-15 16:24:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2021-09-15 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39902</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s12: [3] Corrente di stringa fu...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-15 16:17:00</td>\n",
       "      <td>2021-09-15 16:24:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2021-09-15 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39903</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s5: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-15 16:17:00</td>\n",
       "      <td>2021-09-15 16:24:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2021-09-15 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39904</th>\n",
       "      <td>1</td>\n",
       "      <td>CSP1.6 V180544 s1: [3] Corrente di stringa fuo...</td>\n",
       "      <td>Allarme string-box</td>\n",
       "      <td>2021-09-15 16:17:00</td>\n",
       "      <td>2021-09-15 16:24:00</td>\n",
       "      <td>Log_stringBox - Medium</td>\n",
       "      <td>2021-09-15 16:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30703 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Inverter                                  Componente Guasto  \\\n",
       "4            1  CSP1.6 V180544 s1: [3] Corrente di stringa fuo...   \n",
       "7            1  CSP1.6 V180544 s10: [3] Corrente di stringa fu...   \n",
       "9            1  CSP1.6 V180544 s10: [3] Corrente di stringa fu...   \n",
       "10           1  CSP1.6 V180544 s2: [3] Corrente di stringa fuo...   \n",
       "11           1  CSP1.6 V180544 s1: [3] Corrente di stringa fuo...   \n",
       "...        ...                                                ...   \n",
       "39900        1  CSP1.6 V180544 s10: [3] Corrente di stringa fu...   \n",
       "39901        1  CSP1.6 V180544 s3: [3] Corrente di stringa fuo...   \n",
       "39902        1  CSP1.6 V180544 s12: [3] Corrente di stringa fu...   \n",
       "39903        1  CSP1.6 V180544 s5: [3] Corrente di stringa fuo...   \n",
       "39904        1  CSP1.6 V180544 s1: [3] Corrente di stringa fuo...   \n",
       "\n",
       "             Causa Guasto              Inizio                 Fine  \\\n",
       "4      Allarme string-box 2018-08-08 13:26:00  2018-08-08 14:52:00   \n",
       "7      Allarme string-box 2018-08-08 14:41:00  2018-08-08 14:52:00   \n",
       "9      Allarme string-box 2018-08-08 15:01:00  2018-08-08 15:26:00   \n",
       "10     Allarme string-box 2018-08-08 15:01:00  2018-08-08 15:26:00   \n",
       "11     Allarme string-box 2018-08-08 15:01:00  2018-08-08 15:12:00   \n",
       "...                   ...                 ...                  ...   \n",
       "39900  Allarme string-box 2021-09-15 16:17:00  2021-09-15 16:31:00   \n",
       "39901  Allarme string-box 2021-09-15 16:17:00  2021-09-15 16:24:00   \n",
       "39902  Allarme string-box 2021-09-15 16:17:00  2021-09-15 16:24:00   \n",
       "39903  Allarme string-box 2021-09-15 16:17:00  2021-09-15 16:24:00   \n",
       "39904  Allarme string-box 2021-09-15 16:17:00  2021-09-15 16:24:00   \n",
       "\n",
       "                         Tipo    Hourly timestamp  \n",
       "4      Log_stringBox - Medium 2018-08-08 14:00:00  \n",
       "7      Log_stringBox - Medium 2018-08-08 14:00:00  \n",
       "9      Log_stringBox - Medium 2018-08-08 15:00:00  \n",
       "10     Log_stringBox - Medium 2018-08-08 15:00:00  \n",
       "11     Log_stringBox - Medium 2018-08-08 15:00:00  \n",
       "...                       ...                 ...  \n",
       "39900  Log_stringBox - Medium 2021-09-15 16:00:00  \n",
       "39901  Log_stringBox - Medium 2021-09-15 16:00:00  \n",
       "39902  Log_stringBox - Medium 2021-09-15 16:00:00  \n",
       "39903  Log_stringBox - Medium 2021-09-15 16:00:00  \n",
       "39904  Log_stringBox - Medium 2021-09-15 16:00:00  \n",
       "\n",
       "[30703 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Filling 21070 hours (68.63 %) not having alarms\n",
      "\n",
      "-------------------- [INV1] OVERVIEW --------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log_stringBox - High</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log_stringBox - Medium</th>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log_stringBox - Medium [Corrente di stringa fuori range]</th>\n",
       "      <td>5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nominal hour</th>\n",
       "      <td>21070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Instances\n",
       "Tipo                                                         \n",
       "Log_stringBox - High                                      188\n",
       "Log_stringBox - Medium                                    493\n",
       "Log_stringBox - Medium [Corrente di stringa fuo...       5659\n",
       "Nominal hour                                            21070"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------- GRAPHICAL PANELS --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vieri/anaconda3/envs/sample/lib/python3.8/site-packages/IPython/core/pylabtools.py:137: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    }
   ],
   "source": [
    "for inv_name in inv_names: \n",
    "    print(\"-\" * 60, inv_name, \"-\" * 60)\n",
    "    \n",
    "    # Filter failire events by inverter number \n",
    "    inv_number = int(inv_name[-1])\n",
    "    inv_alarms = fault_df[fault_df['Inverter'] == inv_number]\n",
    "    \n",
    "    print(\"\\n\"+ \"-\" * 35, \"ALARMS OF THE STRING BOXES CONNECTED TO THE INVERTER\", \"-\" * 35)\n",
    "    display(inv_alarms)\n",
    "    \n",
    "    # Create a sub-category\n",
    "    message_name = 'Corrente di stringa fuori range'\n",
    "    hf_type_name = f'Log_stringBox - Medium [{message_name}]'\n",
    "    cond = inv_alarms['Componente Guasto'].str.contains(message_name)\n",
    "    inv_alarms.loc[cond, 'Tipo'] = hf_type_name\n",
    "    \n",
    "    if drop_high_freq_category:\n",
    "        inv_alarms = inv_alarms[inv_alarms['Tipo'] != type_name]\n",
    "\n",
    "    if filling_empty_hours:\n",
    "        type_name = \"Nominal hour\"\n",
    "        timestamps_ranges = pd.date_range(start = inv_alarms['Hourly timestamp'].iloc[0], \n",
    "                                          end = inv_alarms['Hourly timestamp'].iloc[-1], freq = \"1H\")\n",
    "        \n",
    "        missing_hours = [ts for ts in timestamps_ranges if ts not in inv_alarms['Hourly timestamp'].values]\n",
    "        print(f\"\\n--> Filling {len(missing_hours)} hours ({np.round((len(missing_hours)/len(inv_alarms))*100, 2)} %) \"\\\n",
    "              \"not having alarms\")\n",
    "        \n",
    "        to_add = pd.DataFrame([pd.Series({'Inverter': inv_number, 'Componente Guasto': \"-\", \n",
    "                             'Causa Guasto': \"-\", \"Inizio\" : \"-\", \"Fine\": \"-\", \n",
    "                             \"Tipo\": type_name, 'Hourly timestamp': hour}) \n",
    "                            for hour in missing_hours])\n",
    "        \n",
    "        inv_alarms = pd.concat([inv_alarms, to_add], ignore_index = True)\n",
    "        inv_alarms = inv_alarms.sort_values (by = 'Hourly timestamp')\n",
    "    \n",
    "    # Group alarms\n",
    "    grouped_alarms = inv_alarms.groupby(by = ['Hourly timestamp', 'Tipo'], as_index = False).count()\n",
    "    grouped_alarms = grouped_alarms[['Hourly timestamp', 'Tipo', 'Inverter']].rename(columns = {'Inverter': 'Instances'})\n",
    "    grouped_alarms.sort_values(by = ['Hourly timestamp'], inplace = True)\n",
    "    print(\"\\n\"+ \"-\" * 20, f\"[{inv_name}] OVERVIEW\", \"-\" * 20)\n",
    "    display(grouped_alarms.groupby(by = 'Tipo').count()['Instances'].to_frame().sort_index(ascending = True))\n",
    "    \n",
    "    # Select a small subset\n",
    "    alarm_high_df = grouped_alarms.loc[grouped_alarms['Tipo'] == 'Log_stringBox - High', 'Hourly timestamp']\n",
    "\n",
    "    days_to_include = 7\n",
    "    num_periods = 5\n",
    "    use_main_focus = True\n",
    "    if use_main_focus and len(alarm_high_df) > 0:\n",
    "        periods = []\n",
    "        delta_days = pd.Timedelta(days_to_include, unit = 'days')\n",
    "        \n",
    "        for idk in range(num_periods):\n",
    "            \n",
    "            # Isolate the periods\n",
    "            starting_date = alarm_high_df.sample(1, random_state = idk * 10).iloc[0]\n",
    "            main_focus = (starting_date - delta_days, starting_date + delta_days)\n",
    "            \n",
    "            # Isolate the observations\n",
    "            period_cond = grouped_alarms['Hourly timestamp'].between(main_focus[0], main_focus[1])\n",
    "            selected_period = grouped_alarms[period_cond].reset_index(drop = True)\n",
    "            periods.append(selected_period)\n",
    "\n",
    "    print(\"\\n\"+ \"-\" * 50, f\"GRAPHICAL PANELS\", \"-\" * 50)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows = num_periods, figsize=(30, 7 * num_periods), sharex=False, sharey=False)\n",
    "    fig.suptitle(f'[{system_name}] Inverter N°{inv_number}', fontsize = 50, y = 0.96) # y = 1.15\n",
    "    colors = {\"Nominal hour\": \"tab:green\", \"Log_stringBox - High\": \"black\", \"Log_stringBox - Medium\": \"tab:blue\", \n",
    "              \"Log_stringBox - Medium [Corrente di stringa fuori range]\":\"tab:orange\"}\n",
    "    for idk, period_df in enumerate(periods):\n",
    "        starting_date = period_df.iloc[0, 0]\n",
    "        ending_date = period_df.iloc[-1, 0]\n",
    "        \n",
    "        period_string = f\"FOCUSED PERIOD '{ascii_uppercase[idk]}' ({(ending_date - starting_date).days} days): \"\\\n",
    "                        f\"FROM '{starting_date.strftime('%Y-%m-%d')}' TO '{ending_date.strftime('%Y-%m-%d')}'\"\n",
    "        # PANEL: Figure\n",
    "        axes[idk].set_title(period_string, fontsize = 30, pad = 10)\n",
    "        \n",
    "        # PANEL: Histogram\n",
    "        if empty_hours_to_zero:\n",
    "            nominal_cond = period_df['Tipo'] == type_name\n",
    "            period_df.loc[nominal_cond, 'Instances'] = 0\n",
    "    \n",
    "        sns.barplot(x = period_df['Hourly timestamp'], y = period_df['Instances'], hue = period_df['Tipo'],\n",
    "                    ax = axes[idk], dodge = False, palette = colors)\n",
    "\n",
    "        # PANEL: Graphical parameter\n",
    "        axes[idk].set_xlabel('Date', fontsize = 30)\n",
    "        axes[idk].set_ylabel('Instances', fontsize = 30)\n",
    "        #axes.set_ylim(bottom = 1)\n",
    "\n",
    "        axes[idk].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        axes[idk].xaxis.set_major_locator(AutoDateLocator())\n",
    "        #axes.xaxis.set_minor_locator(DayLocator(interval = 1))\n",
    "        \n",
    "        axes[idk].tick_params(direction='inout', grid_linewidth = 1, labelsize = 20)\n",
    "        axes[idk].tick_params(axis = 'y', direction='inout', grid_linewidth = 1, grid_linestyle = '--', grid_color = \"black\")\n",
    "        #axes.tick_params(which = 'minor', direction='inout', grid_linewidth = 0.5, grid_linestyle = '--')\n",
    "        \n",
    "        axes[idk].legend(prop = {\"size\" : 18})\n",
    "        axes[idk].grid(visible = True, which = 'both', axis = 'both')\n",
    "        \n",
    "        if verbose: \n",
    "            print(period_string)\n",
    "            display(period_df)\n",
    "    \n",
    "    #plt.yticks(fontsize = 20)\n",
    "    #plt.xticks(fontsize = 20)\n",
    "    \n",
    "    fig.autofmt_xdate()\n",
    "    fig.tight_layout(pad = 5)\n",
    "    \n",
    "    #plt.legend(prop = {\"size\":20})\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute alarm matrices\n",
    "    alarmHigh_matrix = generate_num_matrix(grouped_alarms, alarm_type = 'Log_stringBox - High')\n",
    "    alarmMedium_matrix = generate_num_matrix(grouped_alarms, alarm_type = 'Log_stringBox - Medium')\n",
    "    alarmHFMedium_matrix = generate_num_matrix(grouped_alarms, alarm_type = hf_type_name)\n",
    "    \n",
    "    # Compute correlations\n",
    "    high_Medium_corr, _ = stats.pearsonr(alarmHigh_matrix, alarmMedium_matrix)\n",
    "    high_hf_Medium_corr, _ = stats.pearsonr(alarmHigh_matrix, alarmHFMedium_matrix)\n",
    "    \n",
    "    print(\"\\n\"+ \"-\" * 50, f\"CORRELATION BETWEEN ALARMS\", \"-\" * 50)\n",
    "    print(\"CORRELATION (High alarms, Medium Alarms): \", np.round(high_Medium_corr, 4))\n",
    "    print(\"CORRELATION (High alarms, High freq. medium alarms \"\\\n",
    "          f\"(i.e., 'corrente di stringa fuori range')): \", np.round(high_hf_Medium_corr, 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.Series(range(5)) #tmp['Instances']\n",
    "display(x)\n",
    "for win_dim in range(5):\n",
    "    new_x = x.rolling(window = win_dim).sum()\n",
    "    display(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sample]",
   "language": "python",
   "name": "conda-env-sample-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
