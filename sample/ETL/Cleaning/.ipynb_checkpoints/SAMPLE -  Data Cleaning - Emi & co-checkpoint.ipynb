{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "if '../..' not in path:\n",
    "    path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from _library.utils import SYSTEM_NAMES_FULL, load_datasets\n",
    "from scipy.stats import zscore\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/vieri/projects/SAMPLE\n",
      "['Binetto 1', 'Binetto 2', 'Cantore', 'Emi', 'Soleto 1', 'Soleto 2', 'Galatina', 'Verone']\n"
     ]
    }
   ],
   "source": [
    "# Select the main folder \n",
    "%cd /mnt/data/vieri/projects/SAMPLE/\n",
    "\n",
    "# Visualize names of PV systems\n",
    "print(SYSTEM_NAMES_FULL)\n",
    "# --- 0 ---------- 1 --------- 2 ------ 3 ------ 4 --------- 5 --------- 6 -------- 7 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the PV system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV SYSTEM -->  Emi\n"
     ]
    }
   ],
   "source": [
    "system_name = SYSTEM_NAMES_FULL[3]\n",
    "print(\"PV SYSTEM --> \", system_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\t\t\t\tPV SYSTEM --> EMI \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Loading inverter data...\n",
      "EMI: OK, component data loaded (4) --> INV1, INV2, INV3, INV4\n",
      "\n",
      "Loading irradiance values...\n",
      "EMI: OK, raw irradiance data (238822 observations) have been loaded\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "FINISHED!: All datasets have been loaded. (SYS: 4 - IRR FILE: 1)\n",
      "--------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------- \n",
      "EXAMPLE --> Emi: INV1 (FROM '2018-07-27' TO '2021-06-30': 1069 days).\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149899 entries, 0 to 149898\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   Date/Time            149899 non-null  datetime64[ns]\n",
      " 1   Iac R (A)            149899 non-null  int64         \n",
      " 2   Iac S (A)            149899 non-null  int64         \n",
      " 3   Iac T (A)            149899 non-null  int64         \n",
      " 4   Vac R (V)            149899 non-null  int64         \n",
      " 5   Vac S (V)            149899 non-null  int64         \n",
      " 6   Vac T (V)            149899 non-null  int64         \n",
      " 7   Pac R (kW)           149899 non-null  int64         \n",
      " 8   Pac S (kW)           0 non-null       float64       \n",
      " 9   Pac T (kW)           0 non-null       float64       \n",
      " 10  E. totale (kWh)      149899 non-null  float64       \n",
      " 11  Cc 1 (A)             149899 non-null  int64         \n",
      " 12  Vcc 1 (V)            149899 non-null  int64         \n",
      " 13  Allarme              149899 non-null  string        \n",
      " 14  Stato                0 non-null       float64       \n",
      " 15  Inverter temp. (°C)  149899 non-null  int64         \n",
      " 16  Fac (Hz)             0 non-null       float64       \n",
      " 17  Irr. medio (W/mq)    128781 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(10), string(1)\n",
      "memory usage: 20.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Loading the datasets\n",
    "path_file, inv_data, inv_names, raw_irr_data, string_inv_data, string_inv_names = load_datasets(system_name, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pac S (kW)  Pac T (kW)  Stato  Fac (Hz)  Irr. medio (W/mq)  \\\n",
      "count         0.0         0.0    0.0       0.0      128781.000000   \n",
      "mean          NaN         NaN    NaN       NaN         293.305224   \n",
      "std           NaN         NaN    NaN       NaN         295.555958   \n",
      "min           NaN         NaN    NaN       NaN           3.000000   \n",
      "25%           NaN         NaN    NaN       NaN          25.000000   \n",
      "50%           NaN         NaN    NaN       NaN         177.000000   \n",
      "75%           NaN         NaN    NaN       NaN         536.000000   \n",
      "max           NaN         NaN    NaN       NaN        1301.000000   \n",
      "\n",
      "       Inverter temp. (°C)  \n",
      "count        149899.000000  \n",
      "mean           1659.574427  \n",
      "std           10242.864404  \n",
      "min               1.000000  \n",
      "25%              11.000000  \n",
      "50%              17.000000  \n",
      "75%              23.000000  \n",
      "max           65535.000000   \n",
      "\n",
      "VALID TEMP. VALUE: 146141 (97.49%)\n"
     ]
    }
   ],
   "source": [
    "# TASK (EXPLORE): Carry out some descriptive statistics on problematic columns (i.e., those identified through numerical and temporal distribution graphs)\n",
    "to_load = inv_names[0]\n",
    "\n",
    "# Check numerical distribution via some descriptive statistics (mean, IQR, etc)\n",
    "check_emptiness = [\"Pac S (kW)\", \"Pac T (kW)\", \"Stato\", \"Fac (Hz)\"] \n",
    "varibles_to_analyse = [\"Irr. medio (W/mq)\", \"Inverter temp. (°C)\"]\n",
    "for var in [check_emptiness + varibles_to_analyse]:\n",
    "    print(inv_data[to_load][var].describe(), \"\\n\")\n",
    "\n",
    "# Quick check at the invalid temperature values (above the likely physical limit)\n",
    "valid_temperature = 200 # °C\n",
    "valid_tempValue = inv_data[to_load].loc[inv_data[to_load][\"Inverter temp. (°C)\"] <= valid_temperature, :]\n",
    "print(f\"VALID TEMP. VALUE: {len(valid_tempValue)} ({round((len(valid_tempValue)/len(inv_data[to_load]['Inverter temp. (°C)']))*100, 2)}%)\")\n",
    "\n",
    "# FINDINGS: \n",
    "# 1) \"Pac S (kW)\", \"Pac T (kW)\", \"Stato\", \"Fac (Hz)\" --> OK: 0 valid values --> They can be discarded\n",
    "# 2) Irr. medio --> it seems okay (mean, std, IQR, min, max)\n",
    "# 3) Inverter temp [°C] --> Strange \n",
    "#   --->  mean: 1064, std: 8223, IQR: 11-21, max = 65535\n",
    "#   ---> value above 1000 should be analyse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non integer values (that are not NaN values): 0\n",
      "\n",
      "CASTING to Int64: Compute difference to check validity.\n",
      "MEAN (diff): 0.0, STD (diff):0.0\n"
     ]
    }
   ],
   "source": [
    "# TASK (EXPLORE): Check whather a type converstion is necessary?\n",
    "# VARIABLE: Irr. medio (W/mq) --> From 'float64' to int64\n",
    "irr_values = inv_data[to_load][\"Irr. medio (W/mq)\"]\n",
    "non_integer = [value for value in irr_values if not value.is_integer()]\n",
    "non_nanInteger = [value for value in non_integer if not np.isnan(value)]\n",
    "print(\"Number of non integer values (that are not NaN values):\", len(non_nanInteger))\n",
    "\n",
    "# Check its validity \n",
    "integer_irr_values = pd.array(irr_values, dtype=\"Int64\")\n",
    "diff = np.abs(irr_values - integer_irr_values)\n",
    "diff.dropna(inplace = True)\n",
    "mean = np.mean(diff)\n",
    "std = np.std(diff)\n",
    "print(f\"\\nCASTING to Int64: Compute difference to check validity.\\nMEAN (diff): {mean}, STD (diff):{std}\")\n",
    "\n",
    "# FINDIGS: Irradiance values are all integer values, but the empty values (numpy NaN) was forcing the column to be a float number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix uniqueness of the datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysing INV1...\n",
      "DUPLICATE DATES: 10: ['2019-01-22, 15:10', '2019-03-05, 16:20', '2019-03-15, 10:25', '2019-03-15, 10:30', '2019-03-15, 11:40', '2019-05-02, 17:55', '2019-05-31, 11:40', '2020-02-12, 11:15', '2020-07-20, 13:10', '2021-02-10, 12:35'] (Total observations: 48)\n",
      "\n",
      "Analysing 2019-01-22 15:10:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 14265...\n",
      "    Equal observation(s) have been found: [14266]\n",
      "--> Analysing idk: 14266...\n",
      "    Equal observation(s) have been found: [14265]\n",
      "--> Analysing idk: 14267...\n",
      "    Equal observation(s) have been found: [14268]\n",
      "--> Analysing idk: 14268...\n",
      "    Equal observation(s) have been found: [14267]\n",
      "\n",
      "--> OK, discarding the identical observations:  [14266, 14268]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [14265, 14267]\n",
      "    FOCUSING ON IDK: 14265\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 14267\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [14265, 14267]\n",
      "    Keeping the one (idk: 14265) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {14265} \\---/ TO DISCARD (3 out of 4): [14267] + [14266, 14268]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-05 16:20:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 19818...\n",
      "    Equal observation(s) have been found: [19819]\n",
      "--> Analysing idk: 19819...\n",
      "    Equal observation(s) have been found: [19818]\n",
      "--> Analysing idk: 19820...\n",
      "    Equal observation(s) have been found: [19821]\n",
      "--> Analysing idk: 19821...\n",
      "    Equal observation(s) have been found: [19820]\n",
      "\n",
      "--> OK, discarding the identical observations:  [19819, 19821]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [19818, 19820]\n",
      "    FOCUSING ON IDK: 19818\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 19820\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [19818, 19820]\n",
      "    Keeping the one (idk: 19818) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {19818} \\---/ TO DISCARD (3 out of 4): [19820] + [19819, 19821]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-15 10:25:00 - (observations: 6)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21187...\n",
      "    Equal observation(s) have been found: [21188]\n",
      "--> Analysing idk: 21188...\n",
      "    Equal observation(s) have been found: [21187]\n",
      "--> Analysing idk: 21189...\n",
      "    Equal observation(s) have been found: [21192]\n",
      "--> Analysing idk: 21190...\n",
      "    Equal observation(s) have been found: [21191]\n",
      "--> Analysing idk: 21191...\n",
      "    Equal observation(s) have been found: [21190]\n",
      "--> Analysing idk: 21192...\n",
      "    Equal observation(s) have been found: [21189]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21188, 21191, 21192]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [21187, 21189, 21190]\n",
      "    FOCUSING ON IDK: 21187\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 21189\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 21190\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [21189, 21190]\n",
      "    Keeping the one (idk: 21190) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {21190} \\---/ TO DISCARD (5 out of 6): [21187, 21189] + [21188, 21191, 21192]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-15 10:30:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21193...\n",
      "    Equal observation(s) have been found: [21194]\n",
      "--> Analysing idk: 21194...\n",
      "    Equal observation(s) have been found: [21193]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21194]\n",
      "\n",
      "Analysing 2019-03-15 11:40:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21206...\n",
      "    Equal observation(s) have been found: [21207]\n",
      "--> Analysing idk: 21207...\n",
      "    Equal observation(s) have been found: [21206]\n",
      "--> Analysing idk: 21208...\n",
      "    Equal observation(s) have been found: [21209]\n",
      "--> Analysing idk: 21209...\n",
      "    Equal observation(s) have been found: [21208]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21207, 21209]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [21206, 21208]\n",
      "    FOCUSING ON IDK: 21206\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 21208\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {21208} \\---/ TO DISCARD (3 out of 4): [21206] + [21207, 21209]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-02 17:55:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 28540...\n",
      "    Equal observation(s) have been found: [28541, 28542]\n",
      "--> Analysing idk: 28541...\n",
      "    Equal observation(s) have been found: [28540, 28542]\n",
      "--> Analysing idk: 28542...\n",
      "    Equal observation(s) have been found: [28540, 28541]\n",
      "--> Analysing idk: 28543...\n",
      "    Equal observation(s) have been found: [28544, 28545]\n",
      "--> Analysing idk: 28544...\n",
      "    Equal observation(s) have been found: [28543, 28545]\n",
      "--> Analysing idk: 28545...\n",
      "    Equal observation(s) have been found: [28543, 28544]\n",
      "--> Analysing idk: 28546...\n",
      "    Equal observation(s) have been found: [28547, 28548]\n",
      "--> Analysing idk: 28547...\n",
      "    Equal observation(s) have been found: [28546, 28548]\n",
      "--> Analysing idk: 28548...\n",
      "    Equal observation(s) have been found: [28546, 28547]\n",
      "\n",
      "--> OK, discarding the identical observations:  [28541, 28542, 28544, 28545, 28547, 28548]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [28540, 28543, 28546]\n",
      "    FOCUSING ON IDK: 28540\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 28543\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 28546\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [28543, 28546]\n",
      "    Keeping the one (idk: 28546) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {28546} \\---/ TO DISCARD (8 out of 9): [28540, 28543] + [28541, 28542, 28544, 28545, 28547, 28548]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-31 11:40:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 33321...\n",
      "--> Analysing idk: 33322...\n",
      "No equal observations have been found\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [33321, 33322]\n",
      "    FOCUSING ON IDK: 33321\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 33322\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [33321, 33322]\n",
      "    Keeping the one (idk: 33321) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {33321} \\---/ TO DISCARD (1 out of 2): [33322] + []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2020-02-12 11:15:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 72351...\n",
      "    Equal observation(s) have been found: [72352]\n",
      "--> Analysing idk: 72352...\n",
      "    Equal observation(s) have been found: [72351]\n",
      "--> Analysing idk: 72353...\n",
      "    Equal observation(s) have been found: [72354]\n",
      "--> Analysing idk: 72354...\n",
      "    Equal observation(s) have been found: [72353]\n",
      "\n",
      "--> OK, discarding the identical observations:  [72352, 72354]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [72351, 72353]\n",
      "    FOCUSING ON IDK: 72351\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 72353\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [72351, 72353]\n",
      "    Keeping the one (idk: 72351) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {72351} \\---/ TO DISCARD (3 out of 4): [72353] + [72352, 72354]\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysing 2020-07-20 13:10:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 97966...\n",
      "    Equal observation(s) have been found: [97967, 97968]\n",
      "--> Analysing idk: 97967...\n",
      "    Equal observation(s) have been found: [97966, 97968]\n",
      "--> Analysing idk: 97968...\n",
      "    Equal observation(s) have been found: [97966, 97967]\n",
      "--> Analysing idk: 97969...\n",
      "    Equal observation(s) have been found: [97971, 97974]\n",
      "--> Analysing idk: 97970...\n",
      "    Equal observation(s) have been found: [97972, 97973]\n",
      "--> Analysing idk: 97971...\n",
      "    Equal observation(s) have been found: [97969, 97974]\n",
      "--> Analysing idk: 97972...\n",
      "    Equal observation(s) have been found: [97970, 97973]\n",
      "--> Analysing idk: 97973...\n",
      "    Equal observation(s) have been found: [97970, 97972]\n",
      "--> Analysing idk: 97974...\n",
      "    Equal observation(s) have been found: [97969, 97971]\n",
      "\n",
      "--> OK, discarding the identical observations:  [97967, 97968, 97971, 97972, 97973, 97974]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [97966, 97969, 97970]\n",
      "    FOCUSING ON IDK: 97966\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 97969\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 97970\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [97969, 97970]\n",
      "    Keeping the one (idk: 97970) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {97970} \\---/ TO DISCARD (8 out of 9): [97966, 97969] + [97967, 97968, 97971, 97972, 97973, 97974]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2021-02-10 12:35:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 127539...\n",
      "    Equal observation(s) have been found: [127540]\n",
      "--> Analysing idk: 127540...\n",
      "    Equal observation(s) have been found: [127539]\n",
      "--> Analysing idk: 127541...\n",
      "    Equal observation(s) have been found: [127542]\n",
      "--> Analysing idk: 127542...\n",
      "    Equal observation(s) have been found: [127541]\n",
      "\n",
      "--> OK, discarding the identical observations:  [127540, 127542]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [127539, 127541]\n",
      "    FOCUSING ON IDK: 127539\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 127541\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [127539, 127541]\n",
      "    Keeping the one (idk: 127539) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {127539} \\---/ TO DISCARD (3 out of 4): [127541] + [127540, 127542]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TO DELATE (38 out of 48): [14266, 14267, 14268, 19819, 19820, 19821, 21187, 21188, 21189, 21191, 21192, 21194, 21206, 21207, 21209, 28540, 28541, 28542, 28543, 28544, 28545, 28547, 28548, 33322, 72352, 72353, 72354, 97966, 97967, 97968, 97969, 97971, 97972, 97973, 97974, 127540, 127541, 127542]\n",
      "\n",
      "Analysing INV2...\n",
      "DUPLICATE DATES: 10: ['2019-01-22, 15:10', '2019-03-05, 16:20', '2019-03-15, 10:25', '2019-03-15, 10:30', '2019-03-15, 11:40', '2019-05-02, 17:55', '2019-05-31, 11:40', '2020-02-12, 11:15', '2020-07-20, 13:10', '2021-02-10, 12:35'] (Total observations: 48)\n",
      "\n",
      "Analysing 2019-01-22 15:10:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 13970...\n",
      "    Equal observation(s) have been found: [13971]\n",
      "--> Analysing idk: 13971...\n",
      "    Equal observation(s) have been found: [13970]\n",
      "--> Analysing idk: 13972...\n",
      "    Equal observation(s) have been found: [13973]\n",
      "--> Analysing idk: 13973...\n",
      "    Equal observation(s) have been found: [13972]\n",
      "\n",
      "--> OK, discarding the identical observations:  [13971, 13973]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [13970, 13972]\n",
      "    FOCUSING ON IDK: 13970\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 13972\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [13970, 13972]\n",
      "    Keeping the one (idk: 13970) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {13970} \\---/ TO DISCARD (3 out of 4): [13972] + [13971, 13973]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-05 16:20:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 19528...\n",
      "    Equal observation(s) have been found: [19529]\n",
      "--> Analysing idk: 19529...\n",
      "    Equal observation(s) have been found: [19528]\n",
      "--> Analysing idk: 19530...\n",
      "    Equal observation(s) have been found: [19531]\n",
      "--> Analysing idk: 19531...\n",
      "    Equal observation(s) have been found: [19530]\n",
      "\n",
      "--> OK, discarding the identical observations:  [19529, 19531]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [19528, 19530]\n",
      "    FOCUSING ON IDK: 19528\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 19530\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {19530} \\---/ TO DISCARD (3 out of 4): [19528] + [19529, 19531]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-15 10:25:00 - (observations: 6)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 20897...\n",
      "    Equal observation(s) have been found: [20898]\n",
      "--> Analysing idk: 20898...\n",
      "    Equal observation(s) have been found: [20897]\n",
      "--> Analysing idk: 20899...\n",
      "    Equal observation(s) have been found: [20900]\n",
      "--> Analysing idk: 20900...\n",
      "    Equal observation(s) have been found: [20899]\n",
      "--> Analysing idk: 20901...\n",
      "    Equal observation(s) have been found: [20902]\n",
      "--> Analysing idk: 20902...\n",
      "    Equal observation(s) have been found: [20901]\n",
      "\n",
      "--> OK, discarding the identical observations:  [20898, 20900, 20902]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [20897, 20899, 20901]\n",
      "    FOCUSING ON IDK: 20897\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 20899\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 20901\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "\n",
      "--> TO KEEP: {20899} \\---/ TO DISCARD (5 out of 6): [20897, 20901] + [20898, 20900, 20902]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-15 10:30:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 20903...\n",
      "    Equal observation(s) have been found: [20904]\n",
      "--> Analysing idk: 20904...\n",
      "    Equal observation(s) have been found: [20903]\n",
      "\n",
      "--> OK, discarding the identical observations:  [20904]\n",
      "\n",
      "Analysing 2019-03-15 11:40:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 20916...\n",
      "    Equal observation(s) have been found: [20917]\n",
      "--> Analysing idk: 20917...\n",
      "    Equal observation(s) have been found: [20916]\n",
      "--> Analysing idk: 20918...\n",
      "    Equal observation(s) have been found: [20919]\n",
      "--> Analysing idk: 20919...\n",
      "    Equal observation(s) have been found: [20918]\n",
      "\n",
      "--> OK, discarding the identical observations:  [20917, 20919]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [20916, 20918]\n",
      "    FOCUSING ON IDK: 20916\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 20918\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {20918} \\---/ TO DISCARD (3 out of 4): [20916] + [20917, 20919]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-02 17:55:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 28576...\n",
      "    Equal observation(s) have been found: [28577, 28580]\n",
      "--> Analysing idk: 28577...\n",
      "    Equal observation(s) have been found: [28576, 28580]\n",
      "--> Analysing idk: 28578...\n",
      "    Equal observation(s) have been found: [28579, 28584]\n",
      "--> Analysing idk: 28579...\n",
      "    Equal observation(s) have been found: [28578, 28584]\n",
      "--> Analysing idk: 28580...\n",
      "    Equal observation(s) have been found: [28576, 28577]\n",
      "--> Analysing idk: 28581...\n",
      "    Equal observation(s) have been found: [28582, 28583]\n",
      "--> Analysing idk: 28582...\n",
      "    Equal observation(s) have been found: [28581, 28583]\n",
      "--> Analysing idk: 28583...\n",
      "    Equal observation(s) have been found: [28581, 28582]\n",
      "--> Analysing idk: 28584...\n",
      "    Equal observation(s) have been found: [28578, 28579]\n",
      "\n",
      "--> OK, discarding the identical observations:  [28577, 28579, 28580, 28582, 28583, 28584]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [28576, 28578, 28581]\n",
      "    FOCUSING ON IDK: 28576\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 28578\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 28581\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [28578, 28581]\n",
      "    Keeping the one (idk: 28581) with the less delta with the previous and next observations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> TO KEEP: {28581} \\---/ TO DISCARD (8 out of 9): [28576, 28578] + [28577, 28579, 28580, 28582, 28583, 28584]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-31 11:40:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 33360...\n",
      "--> Analysing idk: 33361...\n",
      "No equal observations have been found\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [33360, 33361]\n",
      "    FOCUSING ON IDK: 33360\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 33361\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [33360, 33361]\n",
      "    Keeping the one (idk: 33360) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {33360} \\---/ TO DISCARD (1 out of 2): [33361] + []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2020-02-12 11:15:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 71892...\n",
      "    Equal observation(s) have been found: [71893]\n",
      "--> Analysing idk: 71893...\n",
      "    Equal observation(s) have been found: [71892]\n",
      "--> Analysing idk: 71894...\n",
      "    Equal observation(s) have been found: [71895]\n",
      "--> Analysing idk: 71895...\n",
      "    Equal observation(s) have been found: [71894]\n",
      "\n",
      "--> OK, discarding the identical observations:  [71893, 71895]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [71892, 71894]\n",
      "    FOCUSING ON IDK: 71892\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 71894\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {71894} \\---/ TO DISCARD (3 out of 4): [71892] + [71893, 71895]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2020-07-20 13:10:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 97578...\n",
      "    Equal observation(s) have been found: [97579, 97580]\n",
      "--> Analysing idk: 97579...\n",
      "    Equal observation(s) have been found: [97578, 97580]\n",
      "--> Analysing idk: 97580...\n",
      "    Equal observation(s) have been found: [97578, 97579]\n",
      "--> Analysing idk: 97581...\n",
      "    Equal observation(s) have been found: [97582, 97586]\n",
      "--> Analysing idk: 97582...\n",
      "    Equal observation(s) have been found: [97581, 97586]\n",
      "--> Analysing idk: 97583...\n",
      "    Equal observation(s) have been found: [97584, 97585]\n",
      "--> Analysing idk: 97584...\n",
      "    Equal observation(s) have been found: [97583, 97585]\n",
      "--> Analysing idk: 97585...\n",
      "    Equal observation(s) have been found: [97583, 97584]\n",
      "--> Analysing idk: 97586...\n",
      "    Equal observation(s) have been found: [97581, 97582]\n",
      "\n",
      "--> OK, discarding the identical observations:  [97579, 97580, 97582, 97584, 97585, 97586]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [97578, 97581, 97583]\n",
      "    FOCUSING ON IDK: 97578\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 97581\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 97583\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [97581, 97583]\n",
      "    Keeping the one (idk: 97583) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {97583} \\---/ TO DISCARD (8 out of 9): [97578, 97581] + [97579, 97580, 97582, 97584, 97585, 97586]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2021-02-10 12:35:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 127169...\n",
      "    Equal observation(s) have been found: [127170]\n",
      "--> Analysing idk: 127170...\n",
      "    Equal observation(s) have been found: [127169]\n",
      "--> Analysing idk: 127171...\n",
      "    Equal observation(s) have been found: [127172]\n",
      "--> Analysing idk: 127172...\n",
      "    Equal observation(s) have been found: [127171]\n",
      "\n",
      "--> OK, discarding the identical observations:  [127170, 127172]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [127169, 127171]\n",
      "    FOCUSING ON IDK: 127169\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 127171\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {127171} \\---/ TO DISCARD (3 out of 4): [127169] + [127170, 127172]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TO DELATE (38 out of 48): [13971, 13972, 13973, 19528, 19529, 19531, 20897, 20898, 20900, 20901, 20902, 20904, 20916, 20917, 20919, 28576, 28577, 28578, 28579, 28580, 28582, 28583, 28584, 33361, 71892, 71893, 71895, 97578, 97579, 97580, 97581, 97582, 97584, 97585, 97586, 127169, 127170, 127172]\n",
      "\n",
      "Analysing INV3...\n",
      "DUPLICATE DATES: 10: ['2019-01-22, 15:10', '2019-03-05, 16:20', '2019-03-15, 10:25', '2019-03-15, 10:30', '2019-03-15, 11:40', '2019-05-02, 17:55', '2019-05-31, 11:40', '2020-02-12, 11:15', '2020-07-20, 13:10', '2021-02-10, 12:35'] (Total observations: 48)\n",
      "\n",
      "Analysing 2019-01-22 15:10:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 14366...\n",
      "    Equal observation(s) have been found: [14367]\n",
      "--> Analysing idk: 14367...\n",
      "    Equal observation(s) have been found: [14366]\n",
      "--> Analysing idk: 14368...\n",
      "    Equal observation(s) have been found: [14369]\n",
      "--> Analysing idk: 14369...\n",
      "    Equal observation(s) have been found: [14368]\n",
      "\n",
      "--> OK, discarding the identical observations:  [14367, 14369]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [14366, 14368]\n",
      "    FOCUSING ON IDK: 14366\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 14368\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {14368} \\---/ TO DISCARD (3 out of 4): [14366] + [14367, 14369]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-05 16:20:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 19931...\n",
      "    Equal observation(s) have been found: [19932]\n",
      "--> Analysing idk: 19932...\n",
      "    Equal observation(s) have been found: [19931]\n",
      "--> Analysing idk: 19933...\n",
      "    Equal observation(s) have been found: [19934]\n",
      "--> Analysing idk: 19934...\n",
      "    Equal observation(s) have been found: [19933]\n",
      "\n",
      "--> OK, discarding the identical observations:  [19932, 19934]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [19931, 19933]\n",
      "    FOCUSING ON IDK: 19931\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 19933\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {19933} \\---/ TO DISCARD (3 out of 4): [19931] + [19932, 19934]\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysing 2019-03-15 10:25:00 - (observations: 6)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21300...\n",
      "    Equal observation(s) have been found: [21301]\n",
      "--> Analysing idk: 21301...\n",
      "    Equal observation(s) have been found: [21300]\n",
      "--> Analysing idk: 21302...\n",
      "    Equal observation(s) have been found: [21303]\n",
      "--> Analysing idk: 21303...\n",
      "    Equal observation(s) have been found: [21302]\n",
      "--> Analysing idk: 21304...\n",
      "    Equal observation(s) have been found: [21305]\n",
      "--> Analysing idk: 21305...\n",
      "    Equal observation(s) have been found: [21304]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21301, 21303, 21305]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [21300, 21302, 21304]\n",
      "    FOCUSING ON IDK: 21300\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 21302\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 21304\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [21300, 21302, 21304]\n",
      "    Keeping the one (idk: 21300) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {21300} \\---/ TO DISCARD (5 out of 6): [21302, 21304] + [21301, 21303, 21305]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-15 10:30:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21306...\n",
      "    Equal observation(s) have been found: [21307]\n",
      "--> Analysing idk: 21307...\n",
      "    Equal observation(s) have been found: [21306]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21307]\n",
      "\n",
      "Analysing 2019-03-15 11:40:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21319...\n",
      "    Equal observation(s) have been found: [21320]\n",
      "--> Analysing idk: 21320...\n",
      "    Equal observation(s) have been found: [21319]\n",
      "--> Analysing idk: 21321...\n",
      "    Equal observation(s) have been found: [21322]\n",
      "--> Analysing idk: 21322...\n",
      "    Equal observation(s) have been found: [21321]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21320, 21322]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [21319, 21321]\n",
      "    FOCUSING ON IDK: 21319\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 21321\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [21319, 21321]\n",
      "    Keeping the one (idk: 21319) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {21319} \\---/ TO DISCARD (3 out of 4): [21321] + [21320, 21322]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-02 17:55:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 28998...\n",
      "    Equal observation(s) have been found: [28999, 29000]\n",
      "--> Analysing idk: 28999...\n",
      "    Equal observation(s) have been found: [28998, 29000]\n",
      "--> Analysing idk: 29000...\n",
      "    Equal observation(s) have been found: [28998, 28999]\n",
      "--> Analysing idk: 29001...\n",
      "    Equal observation(s) have been found: [29002, 29006]\n",
      "--> Analysing idk: 29002...\n",
      "    Equal observation(s) have been found: [29001, 29006]\n",
      "--> Analysing idk: 29003...\n",
      "    Equal observation(s) have been found: [29004, 29005]\n",
      "--> Analysing idk: 29004...\n",
      "    Equal observation(s) have been found: [29003, 29005]\n",
      "--> Analysing idk: 29005...\n",
      "    Equal observation(s) have been found: [29003, 29004]\n",
      "--> Analysing idk: 29006...\n",
      "    Equal observation(s) have been found: [29001, 29002]\n",
      "\n",
      "--> OK, discarding the identical observations:  [28999, 29000, 29002, 29004, 29005, 29006]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [28998, 29001, 29003]\n",
      "    FOCUSING ON IDK: 28998\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 29001\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 29003\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [29001, 29003]\n",
      "    Keeping the one (idk: 29003) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {29003} \\---/ TO DISCARD (8 out of 9): [28998, 29001] + [28999, 29000, 29002, 29004, 29005, 29006]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-31 11:40:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 33785...\n",
      "--> Analysing idk: 33786...\n",
      "No equal observations have been found\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [33785, 33786]\n",
      "    FOCUSING ON IDK: 33785\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 33786\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [33785, 33786]\n",
      "    Keeping the one (idk: 33785) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {33785} \\---/ TO DISCARD (1 out of 2): [33786] + []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2020-02-12 11:15:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 72824...\n",
      "    Equal observation(s) have been found: [72825]\n",
      "--> Analysing idk: 72825...\n",
      "    Equal observation(s) have been found: [72824]\n",
      "--> Analysing idk: 72826...\n",
      "    Equal observation(s) have been found: [72827]\n",
      "--> Analysing idk: 72827...\n",
      "    Equal observation(s) have been found: [72826]\n",
      "\n",
      "--> OK, discarding the identical observations:  [72825, 72827]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [72824, 72826]\n",
      "    FOCUSING ON IDK: 72824\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 72826\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {72826} \\---/ TO DISCARD (3 out of 4): [72824] + [72825, 72827]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2020-07-20 13:10:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 98475...\n",
      "    Equal observation(s) have been found: [98476, 98479]\n",
      "--> Analysing idk: 98476...\n",
      "    Equal observation(s) have been found: [98475, 98479]\n",
      "--> Analysing idk: 98477...\n",
      "    Equal observation(s) have been found: [98478, 98483]\n",
      "--> Analysing idk: 98478...\n",
      "    Equal observation(s) have been found: [98477, 98483]\n",
      "--> Analysing idk: 98479...\n",
      "    Equal observation(s) have been found: [98475, 98476]\n",
      "--> Analysing idk: 98480...\n",
      "    Equal observation(s) have been found: [98481, 98482]\n",
      "--> Analysing idk: 98481...\n",
      "    Equal observation(s) have been found: [98480, 98482]\n",
      "--> Analysing idk: 98482...\n",
      "    Equal observation(s) have been found: [98480, 98481]\n",
      "--> Analysing idk: 98483...\n",
      "    Equal observation(s) have been found: [98477, 98478]\n",
      "\n",
      "--> OK, discarding the identical observations:  [98476, 98478, 98479, 98481, 98482, 98483]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [98475, 98477, 98480]\n",
      "    FOCUSING ON IDK: 98475\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 98477\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 98480\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [98477, 98480]\n",
      "    Keeping the one (idk: 98480) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {98480} \\---/ TO DISCARD (8 out of 9): [98475, 98477] + [98476, 98478, 98479, 98481, 98482, 98483]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2021-02-10 12:35:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 127031...\n",
      "    Equal observation(s) have been found: [127032]\n",
      "--> Analysing idk: 127032...\n",
      "    Equal observation(s) have been found: [127031]\n",
      "--> Analysing idk: 127033...\n",
      "    Equal observation(s) have been found: [127034]\n",
      "--> Analysing idk: 127034...\n",
      "    Equal observation(s) have been found: [127033]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> OK, discarding the identical observations:  [127032, 127034]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [127031, 127033]\n",
      "    FOCUSING ON IDK: 127031\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 127033\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [127031, 127033]\n",
      "    Keeping the one (idk: 127031) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {127031} \\---/ TO DISCARD (3 out of 4): [127033] + [127032, 127034]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TO DELATE (38 out of 48): [14366, 14367, 14369, 19931, 19932, 19934, 21301, 21302, 21303, 21304, 21305, 21307, 21320, 21321, 21322, 28998, 28999, 29000, 29001, 29002, 29004, 29005, 29006, 33786, 72824, 72825, 72827, 98475, 98476, 98477, 98478, 98479, 98481, 98482, 98483, 127032, 127033, 127034]\n",
      "\n",
      "Analysing INV4...\n",
      "DUPLICATE DATES: 10: ['2019-01-22, 15:10', '2019-03-05, 16:20', '2019-03-15, 10:25', '2019-03-15, 10:30', '2019-03-15, 11:40', '2019-05-02, 17:55', '2019-05-31, 11:40', '2020-02-12, 11:15', '2020-07-20, 13:10', '2021-02-10, 12:35'] (Total observations: 48)\n",
      "\n",
      "Analysing 2019-01-22 15:10:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 14365...\n",
      "    Equal observation(s) have been found: [14366]\n",
      "--> Analysing idk: 14366...\n",
      "    Equal observation(s) have been found: [14365]\n",
      "--> Analysing idk: 14367...\n",
      "    Equal observation(s) have been found: [14368]\n",
      "--> Analysing idk: 14368...\n",
      "    Equal observation(s) have been found: [14367]\n",
      "\n",
      "--> OK, discarding the identical observations:  [14366, 14368]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [14365, 14367]\n",
      "    FOCUSING ON IDK: 14365\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 14367\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {14367} \\---/ TO DISCARD (3 out of 4): [14365] + [14366, 14368]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-05 16:20:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 19937...\n",
      "    Equal observation(s) have been found: [19938]\n",
      "--> Analysing idk: 19938...\n",
      "    Equal observation(s) have been found: [19937]\n",
      "--> Analysing idk: 19939...\n",
      "    Equal observation(s) have been found: [19940]\n",
      "--> Analysing idk: 19940...\n",
      "    Equal observation(s) have been found: [19939]\n",
      "\n",
      "--> OK, discarding the identical observations:  [19938, 19940]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [19937, 19939]\n",
      "    FOCUSING ON IDK: 19937\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 19939\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [19937, 19939]\n",
      "    Keeping the one (idk: 19937) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {19937} \\---/ TO DISCARD (3 out of 4): [19939] + [19938, 19940]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-15 10:25:00 - (observations: 6)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21305...\n",
      "    Equal observation(s) have been found: [21307]\n",
      "--> Analysing idk: 21306...\n",
      "    Equal observation(s) have been found: [21310]\n",
      "--> Analysing idk: 21307...\n",
      "    Equal observation(s) have been found: [21305]\n",
      "--> Analysing idk: 21308...\n",
      "    Equal observation(s) have been found: [21309]\n",
      "--> Analysing idk: 21309...\n",
      "    Equal observation(s) have been found: [21308]\n",
      "--> Analysing idk: 21310...\n",
      "    Equal observation(s) have been found: [21306]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21307, 21309, 21310]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [21305, 21306, 21308]\n",
      "    FOCUSING ON IDK: 21305\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 21306\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 21308\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [21306, 21308]\n",
      "    Keeping the one (idk: 21308) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {21308} \\---/ TO DISCARD (5 out of 6): [21305, 21306] + [21307, 21309, 21310]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-03-15 10:30:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21311...\n",
      "    Equal observation(s) have been found: [21312]\n",
      "--> Analysing idk: 21312...\n",
      "    Equal observation(s) have been found: [21311]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21312]\n",
      "\n",
      "Analysing 2019-03-15 11:40:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 21324...\n",
      "    Equal observation(s) have been found: [21325]\n",
      "--> Analysing idk: 21325...\n",
      "    Equal observation(s) have been found: [21324]\n",
      "--> Analysing idk: 21326...\n",
      "    Equal observation(s) have been found: [21327]\n",
      "--> Analysing idk: 21327...\n",
      "    Equal observation(s) have been found: [21326]\n",
      "\n",
      "--> OK, discarding the identical observations:  [21325, 21327]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [21324, 21326]\n",
      "    FOCUSING ON IDK: 21324\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 21326\n",
      "    Valid observation.\n",
      "\n",
      "--> TO KEEP: {21326} \\---/ TO DISCARD (3 out of 4): [21324] + [21325, 21327]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-02 17:55:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 29004...\n",
      "    Equal observation(s) have been found: [29005, 29006]\n",
      "--> Analysing idk: 29005...\n",
      "    Equal observation(s) have been found: [29004, 29006]\n",
      "--> Analysing idk: 29006...\n",
      "    Equal observation(s) have been found: [29004, 29005]\n",
      "--> Analysing idk: 29007...\n",
      "    Equal observation(s) have been found: [29008, 29009]\n",
      "--> Analysing idk: 29008...\n",
      "    Equal observation(s) have been found: [29007, 29009]\n",
      "--> Analysing idk: 29009...\n",
      "    Equal observation(s) have been found: [29007, 29008]\n",
      "--> Analysing idk: 29010...\n",
      "    Equal observation(s) have been found: [29011, 29012]\n",
      "--> Analysing idk: 29011...\n",
      "    Equal observation(s) have been found: [29010, 29012]\n",
      "--> Analysing idk: 29012...\n",
      "    Equal observation(s) have been found: [29010, 29011]\n",
      "\n",
      "--> OK, discarding the identical observations:  [29005, 29006, 29008, 29009, 29011, 29012]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [29004, 29007, 29010]\n",
      "    FOCUSING ON IDK: 29004\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 29007\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 29010\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [29007, 29010]\n",
      "    Keeping the one (idk: 29010) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {29010} \\---/ TO DISCARD (8 out of 9): [29004, 29007] + [29005, 29006, 29008, 29009, 29011, 29012]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2019-05-31 11:40:00 - (observations: 2)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 33791...\n",
      "--> Analysing idk: 33792...\n",
      "No equal observations have been found\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [33791, 33792]\n",
      "    FOCUSING ON IDK: 33791\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 33792\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "33791 -  33792 - 33793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Iac R (A)</th>\n",
       "      <th>Iac S (A)</th>\n",
       "      <th>Iac T (A)</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "      <th>Pac R (kW)</th>\n",
       "      <th>E. totale (kWh)</th>\n",
       "      <th>Cc 1 (A)</th>\n",
       "      <th>Vcc 1 (V)</th>\n",
       "      <th>Allarme</th>\n",
       "      <th>Inverter temp. (°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33791</th>\n",
       "      <td>2019-05-31 11:40:00</td>\n",
       "      <td>533</td>\n",
       "      <td>531</td>\n",
       "      <td>541</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>187</td>\n",
       "      <td>1359427.4</td>\n",
       "      <td>455</td>\n",
       "      <td>409</td>\n",
       "      <td>553701696</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33792</th>\n",
       "      <td>2019-05-31 11:40:00</td>\n",
       "      <td>627</td>\n",
       "      <td>621</td>\n",
       "      <td>633</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>219</td>\n",
       "      <td>1359420.9</td>\n",
       "      <td>527</td>\n",
       "      <td>413</td>\n",
       "      <td>553701696</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33793</th>\n",
       "      <td>2019-05-31 11:50:00</td>\n",
       "      <td>277</td>\n",
       "      <td>267</td>\n",
       "      <td>279</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>94</td>\n",
       "      <td>1359438.3</td>\n",
       "      <td>233</td>\n",
       "      <td>400</td>\n",
       "      <td>553701696</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Iac R (A)  Iac S (A)  Iac T (A)  Vac R (V)  \\\n",
       "33791 2019-05-31 11:40:00        533        531        541        121   \n",
       "33792 2019-05-31 11:40:00        627        621        633        120   \n",
       "33793 2019-05-31 11:50:00        277        267        279        119   \n",
       "\n",
       "       Vac S (V)  Vac T (V)  Pac R (kW)  E. totale (kWh)  Cc 1 (A)  Vcc 1 (V)  \\\n",
       "33791        121        120         187        1359427.4       455        409   \n",
       "33792        119        119         219        1359420.9       527        413   \n",
       "33793        119        119          94        1359438.3       233        400   \n",
       "\n",
       "         Allarme  Inverter temp. (°C)  \n",
       "33791  553701696                   25  \n",
       "33792  553701696                   25  \n",
       "33793  553701696                   23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33792]\n",
      "\n",
      "--> TO KEEP: {33791} \\---/ TO DISCARD (1 out of 2): [33792] + []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2020-02-12 11:15:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 72829...\n",
      "    Equal observation(s) have been found: [72830]\n",
      "--> Analysing idk: 72830...\n",
      "    Equal observation(s) have been found: [72829]\n",
      "--> Analysing idk: 72831...\n",
      "    Equal observation(s) have been found: [72832]\n",
      "--> Analysing idk: 72832...\n",
      "    Equal observation(s) have been found: [72831]\n",
      "\n",
      "--> OK, discarding the identical observations:  [72830, 72832]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [72829, 72831]\n",
      "    FOCUSING ON IDK: 72829\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 72831\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [72829, 72831]\n",
      "    Keeping the one (idk: 72829) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {72829} \\---/ TO DISCARD (3 out of 4): [72831] + [72830, 72832]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2020-07-20 13:10:00 - (observations: 9)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 98507...\n",
      "    Equal observation(s) have been found: [98508, 98509]\n",
      "--> Analysing idk: 98508...\n",
      "    Equal observation(s) have been found: [98507, 98509]\n",
      "--> Analysing idk: 98509...\n",
      "    Equal observation(s) have been found: [98507, 98508]\n",
      "--> Analysing idk: 98510...\n",
      "    Equal observation(s) have been found: [98511, 98512]\n",
      "--> Analysing idk: 98511...\n",
      "    Equal observation(s) have been found: [98510, 98512]\n",
      "--> Analysing idk: 98512...\n",
      "    Equal observation(s) have been found: [98510, 98511]\n",
      "--> Analysing idk: 98513...\n",
      "    Equal observation(s) have been found: [98514, 98515]\n",
      "--> Analysing idk: 98514...\n",
      "    Equal observation(s) have been found: [98513, 98515]\n",
      "--> Analysing idk: 98515...\n",
      "    Equal observation(s) have been found: [98513, 98514]\n",
      "\n",
      "--> OK, discarding the identical observations:  [98508, 98509, 98511, 98512, 98514, 98515]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [98507, 98510, 98513]\n",
      "    FOCUSING ON IDK: 98507\n",
      "    Invalid values of E. total (kWH) the observation will be discarded. \n",
      "    FOCUSING ON IDK: 98510\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 98513\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [98510, 98513]\n",
      "    Keeping the one (idk: 98513) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {98513} \\---/ TO DISCARD (8 out of 9): [98507, 98510] + [98508, 98509, 98511, 98512, 98514, 98515]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysing 2021-02-10 12:35:00 - (observations: 4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--> Analysing idk: 126775...\n",
      "    Equal observation(s) have been found: [126776]\n",
      "--> Analysing idk: 126776...\n",
      "    Equal observation(s) have been found: [126775]\n",
      "--> Analysing idk: 126777...\n",
      "    Equal observation(s) have been found: [126778]\n",
      "--> Analysing idk: 126778...\n",
      "    Equal observation(s) have been found: [126777]\n",
      "\n",
      "--> OK, discarding the identical observations:  [126776, 126778]\n",
      "\n",
      "--> Issue, duplicated observations with different values have been found! --> [126775, 126777]\n",
      "    FOCUSING ON IDK: 126775\n",
      "    Valid observation.\n",
      "    FOCUSING ON IDK: 126777\n",
      "    Valid observation.\n",
      "\n",
      "    Multiple valid duplicated observations have been found. [126775, 126777]\n",
      "    Keeping the one (idk: 126775) with the less delta with the previous and next observations\n",
      "\n",
      "--> TO KEEP: {126775} \\---/ TO DISCARD (3 out of 4): [126777] + [126776, 126778]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TO DELATE (38 out of 48): [14365, 14366, 14368, 19938, 19939, 19940, 21305, 21306, 21307, 21309, 21310, 21312, 21324, 21325, 21327, 29004, 29005, 29006, 29007, 29008, 29009, 29011, 29012, 33792, 72830, 72831, 72832, 98507, 98508, 98509, 98510, 98511, 98512, 98514, 98515, 126776, 126777, 126778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n",
      "/tmp/ipykernel_18245/3828637059.py:38: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  obs = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# Check uniqueness --> Date/time\n",
    "def check_datetime_uniqueness():\n",
    "    index_to_delate = dict()\n",
    "    \n",
    "    for inv_name in inv_names:\n",
    "        df = inv_data[inv_name]\n",
    "        print(f\"\\nAnalysing {inv_name}...\")\n",
    "        \n",
    "        if set(check_emptiness).issubset(df.columns):\n",
    "            df = df.drop(columns = [\"Irr. medio (W/mq)\"] + check_emptiness)\n",
    "\n",
    "        # Check duplicates\n",
    "        condition = df[\"Date/Time\"].duplicated(keep=False)\n",
    "        duplicated_datetime = df[condition]\n",
    "        \n",
    "        # Continue to analyse other inverter in case of no duplicated observations\n",
    "        if len(duplicated_datetime) == 0:\n",
    "            print(f\"Oh, that's good. No duplicated observations have been found for {inv_name}!\")\n",
    "            continue\n",
    "        \n",
    "        # Extraxct unique datetimes\n",
    "        unique_duplicated_dt = [pd.to_datetime(datetime) for datetime in duplicated_datetime[\"Date/Time\"].unique()]\n",
    "        print(f\"DUPLICATE DATES: {len(unique_duplicated_dt)}: {[dt.strftime('%Y-%m-%d, %H:%M') for dt in unique_duplicated_dt]} \"\\\n",
    "              f\"(Total observations: {len(duplicated_datetime)})\")\n",
    "        #display(duplicated_datetime)\n",
    "\n",
    "        # Investigate to this behaviour for a duplicate observations\n",
    "        datetime_to_investigate = unique_duplicated_dt[0]\n",
    "        delta = pd.Timedelta(15, unit=\"minutes\") #datetime.timedelta(minutes=60)\n",
    "        period = (datetime_to_investigate - delta, datetime_to_investigate + delta)\n",
    "        #display(df.loc[df[\"Date/Time\"].between(period[0], period[1]), :])\n",
    "\n",
    "        # Compute difference \n",
    "        to_discard = set()\n",
    "        for datetime in unique_duplicated_dt:\n",
    "            daily_duplicated_indexes = df[df[\"Date/Time\"] == datetime].index\n",
    "            duplicated_obs = df.loc[daily_duplicated_indexes, :].drop(columns = \"Date/Time\")\n",
    "            obs = pd.Series()\n",
    "            \n",
    "            daily_duplicated_indexes\n",
    "            \n",
    "            if len(unique_duplicated_dt) > 300:\n",
    "                clear_output(wait=True)\n",
    "            print(f\"\\nAnalysing {datetime} - (observations: {len(daily_duplicated_indexes)})\")\n",
    "            print(\"-\"*120)\n",
    "            \n",
    "            equal_observations = set()\n",
    "            for idk_check, index_obs in enumerate(daily_duplicated_indexes):\n",
    "                \n",
    "                other_duplicated_obs = duplicated_obs.drop(index_obs, axis=0)\n",
    "\n",
    "                check = duplicated_obs.loc[index_obs,:].eq(other_duplicated_obs)\n",
    "                find_equal_obs = check.all(axis=1)[check.all(axis=1) == True].index.tolist()\n",
    "\n",
    "                print(f\"--> Analysing idk: {index_obs}...\")                \n",
    "                if find_equal_obs:\n",
    "                    print(f\"    Equal observation(s) have been found: {find_equal_obs}\")\n",
    "                    idk_equal_obs = [index_obs] + [idk for idk in find_equal_obs]\n",
    "                    idk_equal_obs.sort()\n",
    "                    \n",
    "                    #display(duplicated_obs.loc[idk_equal_obs, :])\n",
    "                    #idk_equal_obs = [idk for idk in find_equal_obs]\n",
    "\n",
    "                    # Save pairs of equal duplicated observations\n",
    "                    equal_observations.add(tuple(idk_equal_obs))\n",
    "   \n",
    "            # Keep the first equal and discard the other equal observations\n",
    "            duplicated_diff_obs = sorted([obs_to_discard for pairs in equal_observations for obs_to_discard in pairs[1:]])\n",
    "            \n",
    "            if len(duplicated_diff_obs) != 0:\n",
    "                to_discard.update(duplicated_diff_obs)\n",
    "                print(\"\\n--> OK, discarding the identical observations: \", duplicated_diff_obs)\n",
    "            else:\n",
    "                print(\"No equal observations have been found\")\n",
    "        \n",
    "            # Highlight potential issues: same timestamp not equal values\n",
    "            remaining_duplicated_obs = sorted(set(daily_duplicated_indexes) - set(duplicated_diff_obs))\n",
    "            \n",
    "            if len(remaining_duplicated_obs) > 1:\n",
    "                print(f\"\\n--> Issue, duplicated observations with different values have been found! --> {remaining_duplicated_obs}\")\n",
    "                \n",
    "                mean_deltas = []\n",
    "                to_discard_strat_2 = []\n",
    "                for idk_observation in remaining_duplicated_obs:\n",
    "                    print(f\"    FOCUSING ON IDK: {idk_observation}\")\n",
    "\n",
    "                    # Compute the idk of previous and upcoming observations\n",
    "                    prev_idk = idk_observation - 1\n",
    "                    if prev_idk in daily_duplicated_indexes:\n",
    "                        prev_idk = idk_observation - len(duplicated_diff_obs) - 1 \n",
    "      \n",
    "                    upcom_idk = idk_observation + 1\n",
    "                    if upcom_idk in daily_duplicated_indexes:\n",
    "                        upcom_idk = idk_observation + len(duplicated_diff_obs) + 1\n",
    "\n",
    "                    # Compute previous and upcoming observations\n",
    "                    obs_kwh = df.loc[idk_observation, :][\"E. totale (kWh)\"]\n",
    "                    prev = df.loc[prev_idk, :][\"E. totale (kWh)\"]\n",
    "                    upcom = df.loc[upcom_idk, :][\"E. totale (kWh)\"]\n",
    "\n",
    "                    # Compute delta\n",
    "                    mean_deltas.append((idk_observation,np.mean([np.abs(obs_kwh - prev),np.abs(upcom - obs_kwh)]) ))\n",
    "\n",
    "                    # Check validity \n",
    "                    if prev <= obs_kwh <= upcom:\n",
    "                        print(\"    Valid observation.\")\n",
    "                    else:\n",
    "                        print(\"    Invalid values of E. total (kWH) the observation will be discarded. \")\n",
    "                        to_discard_strat_2.append(idk_observation)\n",
    "                        \n",
    "                if len(to_discard_strat_2) == len(remaining_duplicated_obs):\n",
    "                    print(prev_idk, \"- \",idk_observation, \"-\", upcom_idk)\n",
    "                    neighbours = df.loc[prev_idk:upcom_idk, :]\n",
    "                    display(neighbours)\n",
    "                    to_discard_strat_2 = to_discard_strat_2[1:]\n",
    "                    print(to_discard_strat_2)\n",
    "                    \n",
    "                # IN CASE: Multiple valid observations (according to the )\n",
    "                if len(remaining_duplicated_obs) - len(to_discard_strat_2) > 1:\n",
    "                    print(\"\\n    Multiple valid duplicated observations have been found. \"\\\n",
    "                          f\"{sorted(set(remaining_duplicated_obs) - set(to_discard_strat_2))}\")\n",
    "\n",
    "                    # Delete deltas of already selected discarted observations\n",
    "                    if to_discard_strat_2:\n",
    "                        idx_to_delate = [item for item in to_discard_strat_2]\n",
    "                        mean_deltas = [delta for delta in mean_deltas if delta[0] not in idx_to_delate]\n",
    "\n",
    "                    # Sort according to the deltas\n",
    "                    mean_deltas.sort(key = lambda item: item[1])\n",
    "\n",
    "                    if len(mean_deltas) >= 3: # Multiple items to discard\n",
    "                        to_discard_strat_2.extend([item[0] for item in mean_deltas[1:]])\n",
    "                    else:\n",
    "                        to_discard_strat_2.append(*[item[0] for item in mean_deltas[1:]])\n",
    "                    print(f\"    Keeping the one (idk: {mean_deltas[0][0]}) with the less delta with the previous and next observations\")                        \n",
    "            \n",
    "                # Add the discarted index found with this stategy\n",
    "                to_discard.update(to_discard_strat_2)\n",
    "                    \n",
    "                # Visualize final outcome for the day\n",
    "                idx_to_discard = to_discard_strat_2 + duplicated_diff_obs\n",
    "                print(f\"\\n--> TO KEEP: {set(daily_duplicated_indexes) - set(idx_to_discard)} \\---/ \"\\\n",
    "                      f\"TO DISCARD ({len(idx_to_discard)} out of {len(daily_duplicated_indexes)}): \"\\\n",
    "                      f\"{sorted(to_discard_strat_2)} + {sorted(duplicated_diff_obs)}\")\n",
    "                print(\"-\"*120)\n",
    "        \n",
    "        # Select the index to remove (keep the first one, as they are the equal)\n",
    "        idx_to_delate = set(obs_to_discard for pairs in equal_observations for obs_to_discard in pairs[1:])\n",
    "        item_to_delate = sorted(idx_to_delate.union(to_discard))\n",
    "        print(f\"TO DELATE ({len(item_to_delate)} out of {len(duplicated_datetime)}):\", item_to_delate)\n",
    "        \n",
    "        # Delate the equal duplicate\n",
    "        index_to_delate[inv_name] = item_to_delate\n",
    "        \n",
    "    return index_to_delate\n",
    "# -------------------------------------------------------------------------------\n",
    "index_to_delate = check_datetime_uniqueness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carry out some transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INV1...\n",
      "--> Discared some duplicated observations (i.e., same timestamps) (38)\n",
      "--> Discared some empty columns (i.e., ['Pac S (kW)', 'Pac T (kW)', 'Stato', 'Fac (Hz)'])\n",
      "--> Removed the column of irradiance values, since it will be re-added after tackling the sampling issue.\n",
      "\n",
      "INV2...\n",
      "--> Discared some duplicated observations (i.e., same timestamps) (38)\n",
      "--> Discared some empty columns (i.e., ['Pac S (kW)', 'Pac T (kW)', 'Stato', 'Fac (Hz)'])\n",
      "--> Removed the column of irradiance values, since it will be re-added after tackling the sampling issue.\n",
      "\n",
      "INV3...\n",
      "--> Discared some duplicated observations (i.e., same timestamps) (38)\n",
      "--> Discared some empty columns (i.e., ['Pac S (kW)', 'Pac T (kW)', 'Stato', 'Fac (Hz)'])\n",
      "--> Removed the column of irradiance values, since it will be re-added after tackling the sampling issue.\n",
      "\n",
      "INV4...\n",
      "--> Discared some duplicated observations (i.e., same timestamps) (38)\n",
      "--> Discared some empty columns (i.e., ['Pac S (kW)', 'Pac T (kW)', 'Stato', 'Fac (Hz)'])\n",
      "--> Removed the column of irradiance values, since it will be re-added after tackling the sampling issue.\n",
      "\n",
      "RAW IRRADIANCE FILE ...\n",
      "--> Renamed the columns to improve readability and compatibility with other datasets\n"
     ]
    }
   ],
   "source": [
    "# TASK: Carry out the necessary stategies to tackle the issues discovered in the above analyses\n",
    "for inv_name in inv_names:\n",
    "    print(f\"\\n{inv_name.upper()}...\")\n",
    "    \n",
    "    # TASK: Delate duplicate observations (same timestamps)\n",
    "    inv_data[inv_name].drop(index = index_to_delate[inv_name], inplace=True)\n",
    "    inv_data[inv_name].reset_index(drop=True, inplace = True)\n",
    "    print(f\"--> Discared some duplicated observations (i.e., same timestamps) ({len(index_to_delate[inv_name])})\")\n",
    "    \n",
    "    # TASK: Delate the columns (i.e., variables) that have been confirmed empty\n",
    "    inv_data[inv_name].drop(columns = check_emptiness, inplace=True)\n",
    "    print(f\"--> Discared some empty columns (i.e., {check_emptiness})\")\n",
    "    \n",
    "     # TASK: Remove the irradiance column that was joined previously --> it'll be re-added after fixing the sampling of both side\n",
    "    inv_data[inv_name].drop(columns = [\"Irr. medio (W/mq)\"], inplace=True)\n",
    "    print(\"--> Removed the column of irradiance values, since it will be re-added after tackling the sampling issue.\")\n",
    "# ---------------------------------------------------------------------------------\n",
    "# TASK: Carry out some minor changes on the \"raw irradiance file\"\n",
    "print(\"\\nRAW IRRADIANCE FILE ...\")\n",
    "# Rename the column of the data\n",
    "raw_irr_data.rename(columns = {\"data\":\"Date/Time\", \"irr. medio 1 W/mq\":\"Irradiance (W/mq)\"}, inplace=True)\n",
    "print(\"--> Renamed the columns to improve readability and compatibility with other datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149861 entries, 0 to 149860\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   Date/Time            149861 non-null  datetime64[ns]\n",
      " 1   Iac R (A)            149861 non-null  int64         \n",
      " 2   Iac S (A)            149861 non-null  int64         \n",
      " 3   Iac T (A)            149861 non-null  int64         \n",
      " 4   Vac R (V)            149861 non-null  int64         \n",
      " 5   Vac S (V)            149861 non-null  int64         \n",
      " 6   Vac T (V)            149861 non-null  int64         \n",
      " 7   Pac R (kW)           149861 non-null  int64         \n",
      " 8   E. totale (kWh)      149861 non-null  float64       \n",
      " 9   Cc 1 (A)             149861 non-null  int64         \n",
      " 10  Vcc 1 (V)            149861 non-null  int64         \n",
      " 11  Allarme              149861 non-null  string        \n",
      " 12  Inverter temp. (°C)  149861 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(10), string(1)\n",
      "memory usage: 14.9 MB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Analysing INV1...\n",
      "Oh, that's good. No duplicated observations have been found for INV1!\n",
      "\n",
      "Analysing INV2...\n",
      "Oh, that's good. No duplicated observations have been found for INV2!\n",
      "\n",
      "Analysing INV3...\n",
      "Oh, that's good. No duplicated observations have been found for INV3!\n",
      "\n",
      "Analysing INV4...\n",
      "Oh, that's good. No duplicated observations have been found for INV4!\n"
     ]
    }
   ],
   "source": [
    "# Check validity of the transformation\n",
    "inv_data[inv_names[0]].info()\n",
    "print(\"-\"*80)\n",
    "index_to_delate = check_datetime_uniqueness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and correct outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# FUNCTION: Find the outliers by adopting the z-score\n",
    "# -----------------------------------------------------\n",
    "def find_outliers(df, threshold = 3, verbose = False): \n",
    "    numerical_df = df.select_dtypes(include = np.number)\n",
    "    \n",
    "    # THE MEASURAMENT: Z-score\n",
    "    # It describes a value's relationship to the mean of a group of values \n",
    "    # It's the number of standard deviations by which the observed value is above/below the mean value of what is being measured\n",
    "    z_score = np.abs(zscore(numerical_df)) \n",
    "\n",
    "    # Filter the observations that are above the threshold (from literature: 3 is a typical cut-off point to detect the outliers)\n",
    "    if len(z_score.columns) == 3:\n",
    "        cond_outlier = (z_score.iloc[:, 0] > threshold) & (z_score.iloc[:, 1] > threshold) & (z_score.iloc[:, 2] > threshold)\n",
    "    elif len(z_score.columns) == 2:\n",
    "         cond_outlier = (z_score.iloc[:, 0] > threshold) & (z_score.iloc[:, 1] > threshold)\n",
    "    else:\n",
    "        cond_outlier = z_score.iloc[:, 0] > threshold \n",
    "\n",
    "    # Find the outliers according to the threshold of the z-scores\n",
    "    outliers_idk = z_score[cond_outlier].index\n",
    "    outliers = df.loc[outliers_idk, :]\n",
    "    \n",
    "    if verbose & len(outliers) != 0:\n",
    "        print(f\"Z-score values (threshold: {threshold})\")\n",
    "        print(\"MIN:\", round(np.min(min(z_score[cond_outlier].values.tolist())), 2), \\\n",
    "              \"\\nMAX:\",round(np.max(max(z_score[cond_outlier].values.tolist())), 2))\n",
    "              \n",
    "        display(z_score[cond_outlier])\n",
    "        \n",
    "    return outliers\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# FUNCTION: Compute a weighted average value according to the observation's neighbours (KNN)\n",
    "# ------------------------------------------------------------------------------------------\n",
    "def weighted_knn(df, idk_position, list_outliers, column,  K = 6, verbose=True):\n",
    "    # Define the interval before and after the position\n",
    "    k_before = K//2 \n",
    "    k_after = K//2\n",
    "    \n",
    "    # Define the range of neighbours \n",
    "    idk_range = np.arange(idk_outlier - k_before, idk_outlier + k_after + 1)\n",
    "    \n",
    "    # Find the indexes of other outliers (for excluding them in the weighted average)\n",
    "    if idk_position in list_outliers:\n",
    "        list_outliers.remove(idk_position)\n",
    "    \n",
    "    # Detect potential outliers in its neighbours\n",
    "    problematic_idk_neighbours = [idk_outlier for idk_outlier in list_outliers if idk_outlier in idk_range]\n",
    "        \n",
    "    if len(problematic_idk_neighbours) != 0:\n",
    "        if verbose:\n",
    "            print(f\"\\nOPS: Problematic IDK neighbours discovered {len(problematic_idk_neighbours)} \"\\\n",
    "                  f\"({round(((len(problematic_idk_neighbours)/len(idk_range))*100), 2)} %) --> {problematic_idk_neighbours}\")\n",
    "        \n",
    "        # Try to increase the number of neighbours \n",
    "        MAX_K = 30\n",
    "        if len(problematic_idk_neighbours) >= K//2:\n",
    "            new_k = K*2 \n",
    "            if new_k <= MAX_K:\n",
    "                if verbose: \n",
    "                    print(f\"Trying with more neighbours ({new_k})...\")\n",
    "                weighted_knn(df, idk_position, list_outliers, column,  K = new_k, verbose=False)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"Reach maximum of K neighbours\")\n",
    "        \n",
    "        # Remove problematic neighbours\n",
    "        idk_range = idk_range[~ np.isin(idk_range, problematic_idk_neighbours)]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nEnd process of increasing number of neighbours (i.e., number of problematic neigbours is acceptable (fewer than K/2)\")\n",
    "            print(f\"The problematic neighbours ({len(problematic_idk_neighbours)}) have been removed from the neighbour list\")\n",
    "    \n",
    "    # Find the neigbourhood \n",
    "    idk_outlier_pos = np.argwhere(idk_range == idk_position)[0][0]\n",
    "    neighbours_idk = np.delete(idk_range, idk_outlier_pos)\n",
    "    \n",
    "    neighbours = np.array(df.loc[neighbours_idk, :][column]) # iloc\n",
    "    outlier_value = df.loc[idk_position, :][column]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nVARIABLE: {column}\")\n",
    "        print(f\"NEIGHBOURES ({len(neighbours)} out of {K}):{neighbours[:idk_outlier_pos]} \\--/ {neighbours[idk_outlier_pos:]}\")\n",
    "    \n",
    "    # Define the weights\n",
    "    dist_idk = [np.abs(idk - idk_position) for idk in neighbours_idk]\n",
    "    penalize = lambda dist: min(dist_idk)/dist if dist != min(dist_idk) else 1 #min(dist_idk)/(1 + (dist/10))\n",
    "    weights = [round(penalize(dist), 2) for dist in dist_idk]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"WEIGHTS:\", weights)\n",
    "\n",
    "    # Compute the weighted average \n",
    "    weighted_average_value = np.average(neighbours, weights = weights)\n",
    "    \n",
    "    # Round and cast the value to an integer value\n",
    "    candidate_value = int(round(weighted_average_value, 0))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"COMPUTED VALUE: {candidate_value}\")\n",
    "        print(\"-\" * 80)\n",
    "    return candidate_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable: *AC voltage values* (Vac R/S/T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVERTER NAME: INV1 \n",
      " --------------------------------------------------------------------------------\n",
      "Z-score values (threshold: 5)\n",
      "MIN: 42.42 \n",
      "MAX: 46.52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59112</th>\n",
       "      <td>42.424222</td>\n",
       "      <td>46.522341</td>\n",
       "      <td>45.31855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vac R (V)  Vac S (V)  Vac T (V)\n",
       "59112  42.424222  46.522341   45.31855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extreme outliers (1) of Vac\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59112</th>\n",
       "      <td>2019-11-12 13:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "59112 2019-11-12 13:00:00          0          0          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier (idk: 59112) and its neighborhood\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59109</th>\n",
       "      <td>2019-11-12 12:40:00</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59110</th>\n",
       "      <td>2019-11-12 12:45:00</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59111</th>\n",
       "      <td>2019-11-12 12:55:00</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59112</th>\n",
       "      <td>2019-11-12 13:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59113</th>\n",
       "      <td>2019-11-12 13:05:00</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59114</th>\n",
       "      <td>2019-11-12 13:10:00</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59115</th>\n",
       "      <td>2019-11-12 13:15:00</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "59109 2019-11-12 12:40:00        111        112        111\n",
       "59110 2019-11-12 12:45:00        111        111        111\n",
       "59111 2019-11-12 12:55:00        113        113        113\n",
       "59112 2019-11-12 13:00:00          0          0          0\n",
       "59113 2019-11-12 13:05:00        115        115        115\n",
       "59114 2019-11-12 13:10:00        118        118        118\n",
       "59115 2019-11-12 13:15:00        117        117        117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VARIABLE: Vac R (V)\n",
      "NEIGHBOURES (6 out of 6):[111 111 113] \\--/ [115 118 117]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac S (V)\n",
      "NEIGHBOURES (6 out of 6):[112 111 113] \\--/ [115 118 117]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac T (V)\n",
      "NEIGHBOURES (6 out of 6):[111 111 113] \\--/ [115 118 117]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "New data (with the filled value(s))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date/Time    2019-11-12 13:00:00\n",
       "Vac R (V)                    114\n",
       "Vac S (V)                    114\n",
       "Vac T (V)                    114\n",
       "Name: 59112, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "INVERTER NAME: INV2 \n",
      " --------------------------------------------------------------------------------\n",
      "Z-score values (threshold: 5)\n",
      "MIN: 41.43 \n",
      "MAX: 46.28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70876</th>\n",
       "      <td>41.429549</td>\n",
       "      <td>46.277999</td>\n",
       "      <td>43.9042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vac R (V)  Vac S (V)  Vac T (V)\n",
       "70876  41.429549  46.277999    43.9042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extreme outliers (1) of Vac\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70876</th>\n",
       "      <td>2020-02-05 13:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "70876 2020-02-05 13:20:00          0          0          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier (idk: 70876) and its neighborhood\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70873</th>\n",
       "      <td>2020-02-05 13:05:00</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70874</th>\n",
       "      <td>2020-02-05 13:10:00</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70875</th>\n",
       "      <td>2020-02-05 13:15:00</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70876</th>\n",
       "      <td>2020-02-05 13:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70877</th>\n",
       "      <td>2020-02-05 13:25:00</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70878</th>\n",
       "      <td>2020-02-05 13:35:00</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70879</th>\n",
       "      <td>2020-02-05 13:40:00</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "70873 2020-02-05 13:05:00        121        121        122\n",
       "70874 2020-02-05 13:10:00        119        119        119\n",
       "70875 2020-02-05 13:15:00        121        120        121\n",
       "70876 2020-02-05 13:20:00          0          0          0\n",
       "70877 2020-02-05 13:25:00        120        120        121\n",
       "70878 2020-02-05 13:35:00        121        120        121\n",
       "70879 2020-02-05 13:40:00        121        121        121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VARIABLE: Vac R (V)\n",
      "NEIGHBOURES (6 out of 6):[121 119 121] \\--/ [120 121 121]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 120\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac S (V)\n",
      "NEIGHBOURES (6 out of 6):[121 119 120] \\--/ [120 120 121]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 120\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac T (V)\n",
      "NEIGHBOURES (6 out of 6):[122 119 121] \\--/ [121 121 121]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 121\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "New data (with the filled value(s))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date/Time    2020-02-05 13:20:00\n",
       "Vac R (V)                    120\n",
       "Vac S (V)                    120\n",
       "Vac T (V)                    121\n",
       "Name: 70876, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "INVERTER NAME: INV3 \n",
      " --------------------------------------------------------------------------------\n",
      "Z-score values (threshold: 5)\n",
      "MIN: 41.28 \n",
      "MAX: 45.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71807</th>\n",
       "      <td>41.280791</td>\n",
       "      <td>45.695119</td>\n",
       "      <td>43.809058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vac R (V)  Vac S (V)  Vac T (V)\n",
       "71807  41.280791  45.695119  43.809058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extreme outliers (1) of Vac\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71807</th>\n",
       "      <td>2020-02-05 13:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "71807 2020-02-05 13:20:00          0          0          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier (idk: 71807) and its neighborhood\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71804</th>\n",
       "      <td>2020-02-05 13:05:00</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71805</th>\n",
       "      <td>2020-02-05 13:10:00</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71806</th>\n",
       "      <td>2020-02-05 13:15:00</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71807</th>\n",
       "      <td>2020-02-05 13:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71808</th>\n",
       "      <td>2020-02-05 13:25:00</td>\n",
       "      <td>120</td>\n",
       "      <td>122</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71809</th>\n",
       "      <td>2020-02-05 13:35:00</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71810</th>\n",
       "      <td>2020-02-05 13:40:00</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "71804 2020-02-05 13:05:00        121        122        122\n",
       "71805 2020-02-05 13:10:00        119        120        120\n",
       "71806 2020-02-05 13:15:00        121        122        121\n",
       "71807 2020-02-05 13:20:00          0          0          0\n",
       "71808 2020-02-05 13:25:00        120        122        121\n",
       "71809 2020-02-05 13:35:00        121        121        121\n",
       "71810 2020-02-05 13:40:00        121        122        121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VARIABLE: Vac R (V)\n",
      "NEIGHBOURES (6 out of 6):[121 119 121] \\--/ [120 121 121]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 120\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac S (V)\n",
      "NEIGHBOURES (6 out of 6):[122 120 122] \\--/ [122 121 122]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 122\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac T (V)\n",
      "NEIGHBOURES (6 out of 6):[122 120 121] \\--/ [121 121 121]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 121\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "New data (with the filled value(s))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date/Time    2020-02-05 13:20:00\n",
       "Vac R (V)                    120\n",
       "Vac S (V)                    122\n",
       "Vac T (V)                    121\n",
       "Name: 71807, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "INVERTER NAME: INV4 \n",
      " --------------------------------------------------------------------------------\n",
      "The extreme outliers (2) of Vac\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67397</th>\n",
       "      <td>2020-01-05 19:00:00</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95538</th>\n",
       "      <td>2020-07-02 17:10:00</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "67397 2020-01-05 19:00:00         51         48         15\n",
       "95538 2020-07-02 17:10:00          9          6          9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier (idk: 67397) and its neighborhood\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67394</th>\n",
       "      <td>2020-01-05 18:45:00</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67395</th>\n",
       "      <td>2020-01-05 18:50:00</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67396</th>\n",
       "      <td>2020-01-05 18:55:00</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67397</th>\n",
       "      <td>2020-01-05 19:00:00</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67398</th>\n",
       "      <td>2020-01-05 19:10:00</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67399</th>\n",
       "      <td>2020-01-05 19:15:00</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67400</th>\n",
       "      <td>2020-01-05 19:20:00</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "67394 2020-01-05 18:45:00        113        114        113\n",
       "67395 2020-01-05 18:50:00        113        114        113\n",
       "67396 2020-01-05 18:55:00        114        114        113\n",
       "67397 2020-01-05 19:00:00         51         48         15\n",
       "67398 2020-01-05 19:10:00        114        114        113\n",
       "67399 2020-01-05 19:15:00        114        115        114\n",
       "67400 2020-01-05 19:20:00        114        114        113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VARIABLE: Vac R (V)\n",
      "NEIGHBOURES (6 out of 6):[113 113 114] \\--/ [114 114 114]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac S (V)\n",
      "NEIGHBOURES (6 out of 6):[114 114 114] \\--/ [114 115 114]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac T (V)\n",
      "NEIGHBOURES (6 out of 6):[113 113 113] \\--/ [113 114 113]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 113\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "New data (with the filled value(s))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date/Time    2020-01-05 19:00:00\n",
       "Vac R (V)                    114\n",
       "Vac S (V)                    114\n",
       "Vac T (V)                    113\n",
       "Name: 67397, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Outlier (idk: 95538) and its neighborhood\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Vac R (V)</th>\n",
       "      <th>Vac S (V)</th>\n",
       "      <th>Vac T (V)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95535</th>\n",
       "      <td>2020-07-02 16:50:00</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95536</th>\n",
       "      <td>2020-07-02 16:55:00</td>\n",
       "      <td>116</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95537</th>\n",
       "      <td>2020-07-02 17:00:00</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95538</th>\n",
       "      <td>2020-07-02 17:10:00</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95539</th>\n",
       "      <td>2020-07-02 17:15:00</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95540</th>\n",
       "      <td>2020-07-02 17:20:00</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95541</th>\n",
       "      <td>2020-07-02 17:25:00</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date/Time  Vac R (V)  Vac S (V)  Vac T (V)\n",
       "95535 2020-07-02 16:50:00        114        114        113\n",
       "95536 2020-07-02 16:55:00        116        115        115\n",
       "95537 2020-07-02 17:00:00        114        114        113\n",
       "95538 2020-07-02 17:10:00          9          6          9\n",
       "95539 2020-07-02 17:15:00        114        115        114\n",
       "95540 2020-07-02 17:20:00        114        114        113\n",
       "95541 2020-07-02 17:25:00        113        114        113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VARIABLE: Vac R (V)\n",
      "NEIGHBOURES (6 out of 6):[114 116 114] \\--/ [114 114 113]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac S (V)\n",
      "NEIGHBOURES (6 out of 6):[114 115 114] \\--/ [115 114 114]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VARIABLE: Vac T (V)\n",
      "NEIGHBOURES (6 out of 6):[113 115 113] \\--/ [114 113 113]\n",
      "WEIGHTS: [0.33, 0.5, 1, 1, 0.5, 0.33]\n",
      "COMPUTED VALUE: 114\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "New data (with the filled value(s))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date/Time    2020-07-02 17:10:00\n",
       "Vac R (V)                    114\n",
       "Vac S (V)                    114\n",
       "Vac T (V)                    114\n",
       "Name: 95538, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TASK: A) Analyse and correct the outliers\n",
    "# VARIABLES: AC voltage values (Vac R/S/T)\n",
    "# MOTIVATION: Some invalid values (i.e., zero values) have been detected visually (i.e., numerical distribution graphs)\n",
    "columns = [\"Date/Time\", \"Vac R (V)\", \"Vac S (V)\", \"Vac T (V)\"]\n",
    "\n",
    "# Carry out the analysis (and correction) on all the inverters\n",
    "for inv_name in inv_names:\n",
    "    print(\"INVERTER NAME:\", inv_name, \"\\n\", \"-\"*80)\n",
    "    \n",
    "    # 1A) Detect extreme outliers \n",
    "    # Setting threshold: a very high threshold to detect (and correct) only extreme outliers (e.g. zero values)\n",
    "    # Threshold has been set according to emperical tests (default outlier threshold is equal to 3)\n",
    "    extreme_vac_outlier = find_outliers(inv_data[inv_name][columns], verbose=True, threshold = 5)\n",
    "    \n",
    "    if len(extreme_vac_outlier) == 0:\n",
    "        print(\"Oh, no extreme outliers found. That's good.\\n\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"The extreme outliers ({len(extreme_vac_outlier)}) of Vac\")\n",
    "    display(extreme_vac_outlier)\n",
    "\n",
    "    # 1B) Replacing criterion --> Weighted KNN (k = 6)\n",
    "    # Identfy the index of the outliers \n",
    "    idk_outliers = extreme_vac_outlier.index.tolist()\n",
    "    list_outliers = idk_outliers.copy()\n",
    "    \n",
    "    # Compute and assign the estimated value (weighted average value from its neigbours)\n",
    "    for idk_outlier in idk_outliers:\n",
    "        \n",
    "        # Visualize the outlier and its neighours\n",
    "        print(f\"Outlier (idk: {idk_outlier}) and its neighborhood\")\n",
    "        display(inv_data[inv_name][columns].loc[range(idk_outlier - 3, idk_outlier + 4), :])\n",
    "        \n",
    "        # Compute the estimated value and assign the the original dataframe\n",
    "        inv_data[inv_name].loc[idk_outlier, \"Vac R (V)\"] = weighted_knn(inv_data[inv_name][columns], \n",
    "                                                                        idk_outlier, list_outliers, \"Vac R (V)\")\n",
    "        inv_data[inv_name].loc[idk_outlier, \"Vac S (V)\"] = weighted_knn(inv_data[inv_name][columns], \n",
    "                                                                        idk_outlier, list_outliers, \"Vac S (V)\")\n",
    "        inv_data[inv_name].loc[idk_outlier, \"Vac T (V)\"] = weighted_knn(inv_data[inv_name][columns],\n",
    "                                                                        idk_outlier, list_outliers, \"Vac T (V)\")\n",
    "\n",
    "        # Visualize the outcome\n",
    "        print(\"\\nNew data (with the filled value(s))\")\n",
    "        display(inv_data[inv_name].loc[idk_outlier][columns])\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TASK: A) Analyse and correct the outliers\n",
    "# VARIABLES: AC voltage values (Vac R/S/T)\n",
    "# MOTIVATION: Some invalid values (i.e., zero values) have been detected visually (i.e., numerical distribution graphs)\n",
    "columns = [\"Date/Time\", \"Iac R (A)\", \"Iac S (A)\", \"Iac T (A)\"]\n",
    "\n",
    "# Carry out the analysis (and correction) on all the inverters\n",
    "for inv_name in inv_names[3:4]:\n",
    "    print(\"INVERTER NAME:\", inv_name, \"\\n\", \"-\"*80)\n",
    "    \n",
    "    # 1A) Detect extreme outliers \n",
    "    # Setting threshold: a very high threshold to detect (and correct) only extreme outliers (e.g. zero values)\n",
    "    # Threshold has been set according to emperical tests (default outlier threshold is equal to 3)\n",
    "    extreme_vac_outlier = find_outliers(inv_data[inv_name][columns], verbose=True, threshold = 4)\n",
    "    \n",
    "    if len(extreme_vac_outlier) == 0:\n",
    "        print(\"Oh, no extreme outliers found. That's good.\\n\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"The extreme outliers ({len(extreme_vac_outlier)}) of Vac\")\n",
    "    display(extreme_vac_outlier)\n",
    "\n",
    "    # 1B) Replacing criterion --> Weighted KNN (k = 6)\n",
    "    # Identfy the index of the outliers \n",
    "    idk_outliers = extreme_vac_outlier.index.tolist()\n",
    "    list_outliers = idk_outliers.copy()\n",
    "    \n",
    "    # Compute and assign the estimated value (weighted average value from its neigbours)\n",
    "    for idk_outlier in idk_outliers:\n",
    "        \n",
    "        # Visualize the outlier and its neighours\n",
    "        print(f\"Outlier (idk: {idk_outlier}) and its neighborhood\")\n",
    "        display(inv_data[inv_name][columns].loc[range(idk_outlier - 3, idk_outlier + 4), :])\n",
    "        \n",
    "        # Compute the estimated value and assign the the original dataframe\n",
    "        inv_data[inv_name].loc[idk_outlier, \"Iac R (A)\"] = weighted_knn(idk_outlier, list_outliers, \"Iac R (A)\")\n",
    "        inv_data[inv_name].loc[idk_outlier, \"Iac S (A)\"] = weighted_knn(idk_outlier, list_outliers, \"Iac S (A)\")\n",
    "        inv_data[inv_name].loc[idk_outlier, \"Iac T (A)\"] = weighted_knn(idk_outlier, list_outliers, \"Iac T (A)\")\n",
    "\n",
    "        # Visualize the outcome\n",
    "        print(\"\\nNew data (with the filled value(s))\")\n",
    "        display(inv_data[inv_name].loc[idk_outlier][columns])\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, no outliers found. That's good.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Irradiance values\n",
    "columns = [\"Date/Time\", \"Irradiance (W/mq)\"]\n",
    "irr = raw_irr_data[columns].dropna().copy()\n",
    "irr.reset_index(inplace=True, drop=True)\n",
    "\n",
    "extreme_outliers = find_outliers(irr, verbose=True, threshold = 5)\n",
    "\n",
    "if len(extreme_outliers) == 0:\n",
    "    print(\"Oh, no outliers found. That's good.\\n\")\n",
    "else:\n",
    "    print(f\"The extreme outliers (N = {len(extreme_outliers)}) of the variable 'inverter Temp'\")\n",
    "    display(extreme_outliers)\n",
    "    \n",
    "    idk_outliers = extreme_outliers.index.tolist()\n",
    "    list_outliers = idk_outliers.copy()\n",
    "\n",
    "    for idk, idk_outlier in enumerate(idk_outliers):\n",
    "        print(f\"Outlier {idk +1}/{len(idk_outliers)}: ({irr.loc[idk_outlier, 'Irradiance (W/mq)']} W/mq)\")\n",
    "\n",
    "        # Visualize the outlier and its neighours\n",
    "        print(f\"\\nOutlier (idk: {idk_outlier}) and its neighborhood\")\n",
    "        display(irr.iloc[range(idk_outlier - 3, idk_outlier + 4), :])\n",
    "\n",
    "        # Compute the estimated value and assign the the original dataframe\n",
    "        computed_value = weighted_knn(irr, idk_outlier, list_outliers, \"Irradiance (W/mq)\", verbose=True)\n",
    "        irr.loc[idk_outlier, \"Irradiance (W/mq)\"] = computed_value\n",
    "        print(f\"COMPUTED VALUE: {computed_value}\\n\",\"-\" * 80)\n",
    "\n",
    "        # Visualize the outcome\n",
    "        print(\"\\nNew data (with the filled value(s))\")\n",
    "        display(irr.iloc[range(idk_outlier - 3, idk_outlier + 4)][columns])\n",
    "\n",
    "    print(\"-\" * 40, f\"END correction\",\"-\" * 40)\n",
    "irr[\"Irradiance (W/mq)\"] = irr[\"Irradiance (W/mq)\"].astype(\"Int64\")\n",
    "raw_irr_data = irr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irradiance (W/mq)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>238796.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>186.836517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>270.687225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1301.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Irradiance (W/mq)\n",
       "count      238796.000000\n",
       "mean          186.836517\n",
       "std           270.687225\n",
       "min             3.000000\n",
       "25%             8.000000\n",
       "50%            22.000000\n",
       "75%           286.000000\n",
       "max          1301.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(raw_irr_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable: *Inverter Temp* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 389/389: (65535 °C)\n",
      "COMPUTED VALUE: 12\n",
      " --------------------------------------------------------------------------------\n",
      "---------------------------------------- END INV3 ----------------------------------------\n",
      "INVERTER NAME: INV4 \n",
      " --------------------------------------------------------------------------------\n",
      "Z-score values (threshold: 4)\n",
      "MIN: 51.16 \n",
      "MAX: 51.16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inverter temp. (°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12917</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12923</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12925</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12927</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12930</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12943</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12969</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12978</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12979</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12980</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12981</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12983</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12986</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12987</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12988</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12990</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12999</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13003</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13004</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13005</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13008</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13009</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13010</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18430</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18431</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18769</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78694</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78844</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127251</th>\n",
       "      <td>51.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127258</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127259</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127262</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127263</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127264</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127265</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127266</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127267</th>\n",
       "      <td>51.159046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Inverter temp. (°C)\n",
       "12917             51.159046\n",
       "12923             51.159046\n",
       "12925             51.159046\n",
       "12926             51.159046\n",
       "12927             51.159046\n",
       "12930             51.159046\n",
       "12943             51.159046\n",
       "12969             51.159046\n",
       "12971             51.159046\n",
       "12973             51.159046\n",
       "12974             51.159046\n",
       "12978             51.159046\n",
       "12979             51.159046\n",
       "12980             51.159046\n",
       "12981             51.159046\n",
       "12982             51.159046\n",
       "12983             51.159046\n",
       "12985             51.159046\n",
       "12986             51.157483\n",
       "12987             51.159046\n",
       "12988             51.159046\n",
       "12990             51.159046\n",
       "12991             51.157483\n",
       "12992             51.159046\n",
       "12993             51.157483\n",
       "12994             51.157483\n",
       "12995             51.157483\n",
       "12996             51.159046\n",
       "12998             51.157483\n",
       "12999             51.159046\n",
       "13000             51.159046\n",
       "13001             51.159046\n",
       "13002             51.159046\n",
       "13003             51.159046\n",
       "13004             51.159046\n",
       "13005             51.159046\n",
       "13007             51.157483\n",
       "13008             51.159046\n",
       "13009             51.159046\n",
       "13010             51.159046\n",
       "13011             51.159046\n",
       "13227             51.159046\n",
       "13867             51.159046\n",
       "18430             51.159046\n",
       "18431             51.159046\n",
       "18769             51.159046\n",
       "78694             51.159046\n",
       "78844             51.159046\n",
       "127251            51.157483\n",
       "127258            51.159046\n",
       "127259            51.159046\n",
       "127262            51.159046\n",
       "127263            51.159046\n",
       "127264            51.159046\n",
       "127265            51.159046\n",
       "127266            51.159046\n",
       "127267            51.159046"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extreme outliers (N = 57) of the variable 'inverter Temp'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Inverter temp. (°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12917</th>\n",
       "      <td>2019-01-04 06:55:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12923</th>\n",
       "      <td>2019-01-04 08:00:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12925</th>\n",
       "      <td>2019-01-04 08:20:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>2019-01-04 08:30:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12927</th>\n",
       "      <td>2019-01-04 08:40:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12930</th>\n",
       "      <td>2019-01-04 09:15:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12943</th>\n",
       "      <td>2019-01-04 11:35:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12969</th>\n",
       "      <td>2019-01-04 16:35:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>2019-01-04 16:55:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>2019-01-04 17:15:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>2019-01-04 17:25:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12978</th>\n",
       "      <td>2019-01-04 18:10:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12979</th>\n",
       "      <td>2019-01-04 18:20:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12980</th>\n",
       "      <td>2019-01-04 18:30:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12981</th>\n",
       "      <td>2019-01-04 18:40:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>2019-01-04 18:50:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12983</th>\n",
       "      <td>2019-01-04 19:00:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>2019-01-04 19:25:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12986</th>\n",
       "      <td>2019-01-04 19:35:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12987</th>\n",
       "      <td>2019-01-04 19:45:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12988</th>\n",
       "      <td>2019-01-04 19:55:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12990</th>\n",
       "      <td>2019-01-05 06:00:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>2019-01-05 06:10:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>2019-01-05 06:25:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>2019-01-05 06:35:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>2019-01-05 06:45:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>2019-01-05 06:55:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>2019-01-05 07:05:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>2019-01-05 07:25:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12999</th>\n",
       "      <td>2019-01-05 07:35:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>2019-01-05 07:50:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>2019-01-05 08:00:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>2019-01-05 08:10:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13003</th>\n",
       "      <td>2019-01-05 08:20:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13004</th>\n",
       "      <td>2019-01-05 08:30:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13005</th>\n",
       "      <td>2019-01-05 08:40:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>2019-01-05 09:00:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13008</th>\n",
       "      <td>2019-01-05 09:15:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13009</th>\n",
       "      <td>2019-01-05 09:25:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13010</th>\n",
       "      <td>2019-01-05 09:35:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>2019-01-05 09:45:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>2019-01-08 06:30:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>2019-01-16 08:10:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18430</th>\n",
       "      <td>2019-02-23 08:40:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18431</th>\n",
       "      <td>2019-02-23 08:45:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18769</th>\n",
       "      <td>2019-02-25 14:15:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78694</th>\n",
       "      <td>2020-03-24 06:20:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78844</th>\n",
       "      <td>2020-03-25 08:30:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127251</th>\n",
       "      <td>2021-02-14 06:05:00</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127258</th>\n",
       "      <td>2021-02-14 06:45:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127259</th>\n",
       "      <td>2021-02-14 06:50:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127262</th>\n",
       "      <td>2021-02-14 07:05:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127263</th>\n",
       "      <td>2021-02-14 07:10:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127264</th>\n",
       "      <td>2021-02-14 07:20:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127265</th>\n",
       "      <td>2021-02-14 07:25:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127266</th>\n",
       "      <td>2021-02-14 07:30:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127267</th>\n",
       "      <td>2021-02-14 07:35:00</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date/Time  Inverter temp. (°C)\n",
       "12917  2019-01-04 06:55:00                65535\n",
       "12923  2019-01-04 08:00:00                65535\n",
       "12925  2019-01-04 08:20:00                65535\n",
       "12926  2019-01-04 08:30:00                65535\n",
       "12927  2019-01-04 08:40:00                65535\n",
       "12930  2019-01-04 09:15:00                65535\n",
       "12943  2019-01-04 11:35:00                65535\n",
       "12969  2019-01-04 16:35:00                65535\n",
       "12971  2019-01-04 16:55:00                65535\n",
       "12973  2019-01-04 17:15:00                65535\n",
       "12974  2019-01-04 17:25:00                65535\n",
       "12978  2019-01-04 18:10:00                65535\n",
       "12979  2019-01-04 18:20:00                65535\n",
       "12980  2019-01-04 18:30:00                65535\n",
       "12981  2019-01-04 18:40:00                65535\n",
       "12982  2019-01-04 18:50:00                65535\n",
       "12983  2019-01-04 19:00:00                65535\n",
       "12985  2019-01-04 19:25:00                65535\n",
       "12986  2019-01-04 19:35:00                65533\n",
       "12987  2019-01-04 19:45:00                65535\n",
       "12988  2019-01-04 19:55:00                65535\n",
       "12990  2019-01-05 06:00:00                65535\n",
       "12991  2019-01-05 06:10:00                65533\n",
       "12992  2019-01-05 06:25:00                65535\n",
       "12993  2019-01-05 06:35:00                65533\n",
       "12994  2019-01-05 06:45:00                65533\n",
       "12995  2019-01-05 06:55:00                65533\n",
       "12996  2019-01-05 07:05:00                65535\n",
       "12998  2019-01-05 07:25:00                65533\n",
       "12999  2019-01-05 07:35:00                65535\n",
       "13000  2019-01-05 07:50:00                65535\n",
       "13001  2019-01-05 08:00:00                65535\n",
       "13002  2019-01-05 08:10:00                65535\n",
       "13003  2019-01-05 08:20:00                65535\n",
       "13004  2019-01-05 08:30:00                65535\n",
       "13005  2019-01-05 08:40:00                65535\n",
       "13007  2019-01-05 09:00:00                65533\n",
       "13008  2019-01-05 09:15:00                65535\n",
       "13009  2019-01-05 09:25:00                65535\n",
       "13010  2019-01-05 09:35:00                65535\n",
       "13011  2019-01-05 09:45:00                65535\n",
       "13227  2019-01-08 06:30:00                65535\n",
       "13867  2019-01-16 08:10:00                65535\n",
       "18430  2019-02-23 08:40:00                65535\n",
       "18431  2019-02-23 08:45:00                65535\n",
       "18769  2019-02-25 14:15:00                65535\n",
       "78694  2020-03-24 06:20:00                65535\n",
       "78844  2020-03-25 08:30:00                65535\n",
       "127251 2021-02-14 06:05:00                65533\n",
       "127258 2021-02-14 06:45:00                65535\n",
       "127259 2021-02-14 06:50:00                65535\n",
       "127262 2021-02-14 07:05:00                65535\n",
       "127263 2021-02-14 07:10:00                65535\n",
       "127264 2021-02-14 07:20:00                65535\n",
       "127265 2021-02-14 07:25:00                65535\n",
       "127266 2021-02-14 07:30:00                65535\n",
       "127267 2021-02-14 07:35:00                65535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 1/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 2/57: (65535 °C)\n",
      "COMPUTED VALUE: 2\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 3/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 4/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 5/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 6/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 7/57: (65535 °C)\n",
      "COMPUTED VALUE: 2\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 8/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 9/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 10/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 11/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 12/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 13/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 14/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 15/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 16/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 17/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 18/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 19/57: (65533 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 20/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 21/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 22/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 23/57: (65533 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 24/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 25/57: (65533 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 26/57: (65533 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 27/57: (65533 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 28/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 29/57: (65533 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 30/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 31/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 32/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 33/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 34/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 35/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 36/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 37/57: (65533 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 38/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 39/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 40/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 41/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 42/57: (65535 °C)\n",
      "COMPUTED VALUE: 2\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 43/57: (65535 °C)\n",
      "COMPUTED VALUE: 2\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 44/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 45/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 46/57: (65535 °C)\n",
      "COMPUTED VALUE: 2\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 47/57: (65535 °C)\n",
      "COMPUTED VALUE: 2\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 48/57: (65535 °C)\n",
      "COMPUTED VALUE: 3\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 49/57: (65533 °C)\n",
      "COMPUTED VALUE: 4\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 50/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 51/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 52/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 53/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 54/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 55/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 56/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "Outlier 57/57: (65535 °C)\n",
      "COMPUTED VALUE: 1\n",
      " --------------------------------------------------------------------------------\n",
      "---------------------------------------- END INV4 ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TASK: B) Analyse and correct the outliers\n",
    "# VARIABLES: Inverter Temp\n",
    "# MOTIVATION: Some invalid values have been detected visually (i.e., numerical distribution graphs)\n",
    "# e.g., Detect around 2K observations with a value in the range [65.529 - 65.535 °C]\n",
    "columns = [\"Date/Time\", \"Inverter temp. (°C)\"]\n",
    "\n",
    "# Carry out the analysis (and correction) on all the inverters\n",
    "for inv_name in inv_names:#[3:4]:\n",
    "    print(\"INVERTER NAME:\", inv_name, \"\\n\", \"-\"*80)\n",
    "    \n",
    "    # 1A) Detect extreme outliers \n",
    "    # Setting threshold: a very high threshold to detect (and correct) only extreme outliers (e.g. above 1000 °C)\n",
    "    # Threshold has been set according to emperical tests (default outlier threshold is equal to 3)\n",
    "    extreme_outliers = find_outliers(inv_data[inv_name][columns], verbose=True, threshold = 4)\n",
    "    if len(extreme_outliers) == 0:\n",
    "        print(\"Oh, no outliers found. That's good.\\n\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"The extreme outliers (N = {len(extreme_outliers)}) of the variable 'inverter Temp'\")\n",
    "    display(extreme_outliers)\n",
    "    \n",
    "    # 1B) Replacing criterion --> Weighted KNN (k = 6)\n",
    "    # Identfy the index of the outliers \n",
    "    idk_outliers = extreme_outliers.index.tolist()\n",
    "    list_outliers = idk_outliers.copy()\n",
    "    \n",
    "    # Compute and assign the estimated value (weighted average value from its neigbours)\n",
    "    for idk, idk_outlier in enumerate(idk_outliers):\n",
    "        if len(idk_outliers) > 300:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "        print(f\"Outlier {idk +1}/{len(idk_outliers)}: ({inv_data[inv_name].loc[idk_outlier, 'Inverter temp. (°C)']} °C)\")\n",
    "        \n",
    "        # Visualize the outlier and its neighours\n",
    "        # print(f\"\\nOutlier (idk: {idk_outlier}) and its neighborhood\")\n",
    "        # display(inv_data[inv_name][columns].iloc[range(idk_outlier - 3, idk_outlier + 4), :])\n",
    "        \n",
    "        # Compute the estimated value and assign the the original dataframe\n",
    "        computed_value = weighted_knn(inv_data[inv_name][columns], idk_outlier, list_outliers, \"Inverter temp. (°C)\", \n",
    "                                      verbose=False)\n",
    "        inv_data[inv_name].loc[idk_outlier, \"Inverter temp. (°C)\"] = computed_value\n",
    "        print(f\"COMPUTED VALUE: {computed_value}\\n\",\"-\" * 80)\n",
    "                                                                      \n",
    "        # Visualize the outcome\n",
    "        # print(\"\\nNew data (with the filled value(s))\")\n",
    "        # display(inv_data[inv_name].iloc[range(idk_outlier - 3, idk_outlier + 4)][columns])\n",
    "        \n",
    "    print(\"-\" * 40, f\"END {inv_name}\",\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INV1</th>\n",
       "      <th>INV2</th>\n",
       "      <th>INV3</th>\n",
       "      <th>INV4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149861.00</td>\n",
       "      <td>149636.00</td>\n",
       "      <td>148146.00</td>\n",
       "      <td>149243.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.70</td>\n",
       "      <td>23.29</td>\n",
       "      <td>19.39</td>\n",
       "      <td>21.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.17</td>\n",
       "      <td>7.31</td>\n",
       "      <td>8.46</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            INV1       INV2       INV3       INV4\n",
       "count  149861.00  149636.00  148146.00  149243.00\n",
       "mean       16.70      23.29      19.39      21.61\n",
       "std         8.17       7.31       8.46       6.76\n",
       "min         1.00       1.00       1.00       1.00\n",
       "25%        11.00      19.00      13.00      17.00\n",
       "50%        17.00      25.00      19.00      23.00\n",
       "75%        23.00      29.00      25.00      27.00\n",
       "max        41.00      49.00      45.00      45.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outlier correction is valid for all the 4 inverters!\n"
     ]
    }
   ],
   "source": [
    "# TASK: B2) Check validity of the outlier correction for the inverter temperature\n",
    "validity = []\n",
    "inv_temp_values = []\n",
    "for inv_name in inv_names:\n",
    "    inv_temp = inv_data[inv_name][\"Inverter temp. (°C)\"]\n",
    "    inv_temp_values.append(inv_temp.rename(index = inv_name))\n",
    "    \n",
    "    # Check invalid values\n",
    "    threshold_inv_temp = 100\n",
    "    invalid_values = inv_temp.loc[inv_temp >= threshold_inv_temp]\n",
    "    \n",
    "    if len(invalid_values) == 0:\n",
    "        validity.append(True)\n",
    "    else: \n",
    "        validity.append(False)\n",
    "\n",
    "display(pd.concat(inv_temp_values, axis=1, names =inv_names).describe().round(decimals=2))\n",
    "if all(validity):\n",
    "    print(f\"The outlier correction is valid for all the {len(inv_names)} inverters!\")\n",
    "else:\n",
    "    print(\"There is some error in the outlier conversion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final task: Save outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV System -->  EMI\n",
      "The cleaned data for 'INV1' has been saved.\n",
      "The cleaned data for 'INV2' has been saved.\n",
      "The cleaned data for 'INV3' has been saved.\n",
      "The cleaned data for 'INV4' has been saved.\n",
      "\n",
      "The cleaned data for the 'irradiance values' has been saved.\n"
     ]
    }
   ],
   "source": [
    "# FINAL TASK: Save the cleared datasets \n",
    "saving_folder_name = \"Cleaned\"\n",
    "saving_folder_path = path.join(path_file, saving_folder_name)\n",
    "\n",
    "print(\"PV System --> \", system_name.upper())\n",
    "\n",
    "# Create the saving folder\n",
    "if not path.exists(saving_folder_path):\n",
    "    makedirs(saving_folder_path)\n",
    "    print(f\"A new saving folder has been created: {saving_folder_path}\\n\")\n",
    "    \n",
    "# Save the files as CSV files \n",
    "for inv_name in inv_names:\n",
    "    file_name = f\"cleaned_{inv_name.upper()}_data.csv\"\n",
    "    inv_data[inv_name].to_csv(path.join(saving_folder_path, file_name), index=False)\n",
    "    print(f\"The cleaned data for '{inv_name}' has been saved.\")\n",
    "\n",
    "raw_irr_data.to_csv(path.join(saving_folder_path, \"raw_irr_data.csv\"), index=False) \n",
    "print(\"\\nThe cleaned data for the 'irradiance values' has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sample]",
   "language": "python",
   "name": "conda-env-sample-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
